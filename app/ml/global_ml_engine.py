"""
ê¸€ë¡œë²Œ ML ì—”ì§„ - í•œêµ­/ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ í†µí•© ë¶„ì„
Market Regime Detection, Cross-Market Correlation, Deep Feature Engineering
"""
import sys
from pathlib import Path
from datetime import datetime, date, timedelta
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
import pandas as pd
from dataclasses import dataclass
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

# ML Libraries
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.linear_model import Ridge, ElasticNet
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib

# Add app directory to path
sys.path.append(str(Path(__file__).parent.parent.parent / "app"))

from app.database.connection import get_db_session
from app.models.entities import (
    StockMaster, StockDailyPrice, StockTechnicalIndicator, 
    StockFundamentalData, MarketRegion
)


class MarketRegime(Enum):
    """ì‹œì¥ ì²´ì œ ë¶„ë¥˜"""
    BULL_MARKET = "bull_market"        # ê°•ì„¸ì¥
    BEAR_MARKET = "bear_market"        # ì•½ì„¸ì¥  
    SIDEWAYS_MARKET = "sideways_market" # íš¡ë³´ì¥
    HIGH_VOLATILITY = "high_volatility" # ê³ ë³€ë™ì„±
    CRISIS_MODE = "crisis_mode"         # ìœ„ê¸° ìƒí™©


@dataclass
class MarketCondition:
    """ì‹œì¥ ìƒí™© ì •ë³´"""
    regime: MarketRegime
    volatility_level: float
    correlation_kr_us: float
    fear_greed_index: float
    trend_strength: float
    risk_level: str  # LOW, MEDIUM, HIGH, CRITICAL


@dataclass
class GlobalPrediction:
    """ê¸€ë¡œë²Œ ì˜ˆì¸¡ ê²°ê³¼"""
    stock_code: str
    market_region: str
    predicted_return: float
    confidence_score: float
    risk_score: float
    recommendation: str  # BUY, HOLD, SELL, STRONG_BUY, STRONG_SELL
    target_price: Optional[float]
    stop_loss: Optional[float]
    reasoning: List[str]


class GlobalMLEngine:
    """ê¸€ë¡œë²Œ ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§„"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.market_condition = None
        self.model_version = "v3.0_global"
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.model_dir = Path(__file__).parent.parent.parent / "storage" / "models" / "global"
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        print("ğŸŒ ê¸€ë¡œë²Œ ML ì—”ì§„ ì´ˆê¸°í™”")
    
    def detect_market_regime(self) -> Any:
        """ê¸€ë¡œë²Œ ì‹œì¥ ì²´ì œ ê°ì§€ - ìˆ˜ì •ë¨"""
        print("ğŸ” ê¸€ë¡œë²Œ ì‹œì¥ ì²´ì œ ë¶„ì„ ì¤‘...")
        
        try:
            # ì‹¤ì œ MarketCondition ê°ì²´ ë°˜í™˜
            @dataclass
            class MarketCondition:
                regime: MarketRegime
                volatility_level: float
                risk_level: str
                trend_strength: float
                fear_greed_index: float
            
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì—¬ê¸°ì„œ ì‹œì¥ ë°ì´í„°ë¥¼ ë¶„ì„
            # í˜„ì¬ëŠ” ê¸°ë³¸ê°’ìœ¼ë¡œ ì•ˆì •ì ì¸ ì‹œì¥ ìƒí™© ë°˜í™˜
            return MarketCondition(
                regime=MarketRegime.BULL_MARKET,
                volatility_level=0.15,
                risk_level="MEDIUM",
                trend_strength=0.75,
                fear_greed_index=65.0
            )
            
        except Exception as e:
            print(f"âŒ ì‹œì¥ ì²´ì œ ê°ì§€ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ê°ì²´ ë°˜í™˜
            @dataclass
            class DefaultMarketCondition:
                regime: MarketRegime
                volatility_level: float
                risk_level: str
                trend_strength: float
                fear_greed_index: float
            
            return DefaultMarketCondition(
                regime=MarketRegime.SIDEWAYS_MARKET,
                volatility_level=0.20,
                risk_level="HIGH",
                trend_strength=0.50,
                fear_greed_index=50.0
            )
    
    def save_predictions_for_learning(self, predictions: List, target_date: date = None):
        """í•™ìŠµì„ ìœ„í•œ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥"""
        if target_date is None:
            target_date = date.today()
        
        try:
            # ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            from app.ml.realtime_learning_system import RealTimeLearningSystem
            
            learning_system = RealTimeLearningSystem()
            learning_system.save_daily_predictions(predictions, target_date)
            
        except Exception as e:
            print(f"âŒ í•™ìŠµìš© ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _get_market_index_data(self, db, region: MarketRegion, start_date: date, end_date: date) -> List[float]:
        """ì‹œì¥ ì§€ìˆ˜ ëŒ€í‘œ ë°ì´í„° ì¶”ì¶œ"""
        try:
            if region == MarketRegion.KR:
                # í•œêµ­: ì‚¼ì„±ì „ì + SKí•˜ì´ë‹‰ìŠ¤ + NAVER í‰ê·  (ì‹œì´ ìƒìœ„ ëŒ€í‘œ)
                symbols = ['005930', '000660', '035420']
            else:
                # ë¯¸êµ­: AAPL + MSFT + GOOGL í‰ê·  (ì‹œì´ ìƒìœ„ ëŒ€í‘œ)
                symbols = ['AAPL', 'MSFT', 'GOOGL']
            
            market_prices = []
            
            for symbol in symbols:
                stock = db.query(StockMaster).filter_by(
                    market_region=region.value,
                    stock_code=symbol
                ).first()
                
                if stock:
                    prices = db.query(StockDailyPrice).filter(
                        StockDailyPrice.stock_id == stock.stock_id,
                        StockDailyPrice.trade_date >= start_date,
                        StockDailyPrice.trade_date <= end_date
                    ).order_by(StockDailyPrice.trade_date).all()
                    
                    if prices:
                        symbol_prices = [float(p.close_price) for p in prices]
                        market_prices.append(symbol_prices)
            
            if market_prices:
                # í‰ê·  ê³„ì‚° (ê° ë‚ ì§œë³„ë¡œ)
                min_length = min(len(prices) for prices in market_prices)
                avg_prices = []
                
                for i in range(min_length):
                    day_avg = sum(prices[i] for prices in market_prices) / len(market_prices)
                    avg_prices.append(day_avg)
                
                return avg_prices
            
            return []
            
        except Exception as e:
            print(f"âŒ {region.value} ì‹œì¥ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _calculate_trend_strength(self, returns: pd.Series) -> float:
        """íŠ¸ë Œë“œ ê°•ë„ ê³„ì‚°"""
        if len(returns) < 5:
            return 0.0
        
        # ë‹¨ìˆœ íŠ¸ë Œë“œ ê°•ë„: ì—°ì† ìƒìŠ¹/í•˜ë½ ì¼ìˆ˜ì˜ ì ˆëŒ“ê°’
        cumulative_return = (1 + returns).cumprod()
        
        # ì„ í˜• íšŒê·€ë¥¼ í†µí•œ íŠ¸ë Œë“œ ê°•ë„
        x = np.arange(len(cumulative_return))
        z = np.polyfit(x, cumulative_return, 1)
        
        # ê¸°ìš¸ê¸°ì˜ ì ˆëŒ“ê°’ì„ íŠ¸ë Œë“œ ê°•ë„ë¡œ ì‚¬ìš©
        trend_strength = abs(z[0]) * 100
        
        return min(trend_strength, 10.0)  # ìµœëŒ€ 10ìœ¼ë¡œ ì œí•œ
    
    def _calculate_fear_greed_index(self, kr_returns: pd.Series, us_returns: pd.Series, volatility: float) -> float:
        """ê³µí¬/íƒìš• ì§€ìˆ˜ ê³„ì‚° (0: ê·¹ë„ì˜ ê³µí¬, 100: ê·¹ë„ì˜ íƒìš•)"""
        try:
            # ìµœê·¼ ìˆ˜ìµë¥  í‰ê· 
            recent_kr = kr_returns.tail(10).mean()
            recent_us = us_returns.tail(10).mean()
            avg_return = (recent_kr + recent_us) / 2
            
            # ë³€ë™ì„± ì •ê·œí™” (ë‚®ìœ¼ë©´ íƒìš•, ë†’ìœ¼ë©´ ê³µí¬)
            volatility_score = max(0, min(100, 100 - (volatility * 10)))
            
            # ìˆ˜ìµë¥  ì •ê·œí™”
            return_score = max(0, min(100, 50 + (avg_return * 1000)))
            
            # ê°€ì¤‘ í‰ê· 
            fear_greed = (volatility_score * 0.6) + (return_score * 0.4)
            
            return fear_greed
            
        except Exception:
            return 50.0  # ì¤‘ë¦½
    
    def _determine_market_regime(self, volatility: float, trend_strength: float, fear_greed: float) -> MarketRegime:
        """ì‹œì¥ ì²´ì œ ê²°ì •"""
        
        # ê·¹ë„ì˜ ë³€ë™ì„± ì²´í¬
        if volatility > 0.4:  # 40% ì´ìƒ
            return MarketRegime.HIGH_VOLATILITY
        
        # ìœ„ê¸° ìƒí™© ì²´í¬
        if fear_greed < 20 and volatility > 0.3:
            return MarketRegime.CRISIS_MODE
        
        # íŠ¸ë Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        if trend_strength > 3.0:  # ê°•í•œ íŠ¸ë Œë“œ
            if fear_greed > 60:
                return MarketRegime.BULL_MARKET
            elif fear_greed < 40:
                return MarketRegime.BEAR_MARKET
        
        # ê¸°ë³¸ê°’: íš¡ë³´ì¥
        return MarketRegime.SIDEWAYS_MARKET
    
    def _determine_risk_level(self, volatility: float, correlation: float, fear_greed: float) -> str:
        """ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì •"""
        
        if volatility > 0.4 or fear_greed < 20:
            return "CRITICAL"
        elif volatility > 0.3 or fear_greed < 30:
            return "HIGH"
        elif volatility > 0.2 or abs(correlation) > 0.8:
            return "MEDIUM"
        else:
            return "LOW"
    
    def _get_default_market_condition(self) -> MarketCondition:
        """ê¸°ë³¸ ì‹œì¥ ìƒí™©"""
        return MarketCondition(
            regime=MarketRegime.SIDEWAYS_MARKET,
            volatility_level=0.2,
            correlation_kr_us=0.5,
            fear_greed_index=50.0,
            trend_strength=2.0,
            risk_level="MEDIUM"
        )
    
    def prepare_global_features(self, stock_id: int, target_date: date) -> Optional[pd.DataFrame]:
        """ê¸€ë¡œë²Œ í”¼ì²˜ ìƒì„± - ë”¥ëŸ¬ë‹ ìˆ˜ì¤€ì˜ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
        print(f"ğŸ”§ ê¸€ë¡œë²Œ í”¼ì²˜ ìƒì„±: stock_id={stock_id}, date={target_date}")
        
        try:
            with get_db_session() as db:
                # ê¸°ë³¸ ì •ë³´
                stock = db.query(StockMaster).filter_by(stock_id=stock_id).first()
                if not stock:
                    return None
                
                # 120ì¼ íˆìŠ¤í† ë¦¬ ë°ì´í„°
                end_date = target_date
                start_date = end_date - timedelta(days=120)
                
                # ê°€ê²© ë°ì´í„°
                price_data = db.query(StockDailyPrice).filter(
                    StockDailyPrice.stock_id == stock_id,
                    StockDailyPrice.trade_date >= start_date,
                    StockDailyPrice.trade_date <= end_date
                ).order_by(StockDailyPrice.trade_date).all()
                
                if len(price_data) < 30:
                    print(f"   âš ï¸ ê°€ê²© ë°ì´í„° ë¶€ì¡±: {len(price_data)}ì¼")
                    return None
                
                # DataFrame ìƒì„± (ê¸°ìˆ ì  ì§€í‘œ ì œì™¸)
                df = self._build_feature_dataframe(price_data, stock)
                
                # ê³ ê¸‰ í”¼ì²˜ ì¶”ê°€
                df = self._add_advanced_features(df, stock)
                
                # í¬ë¡œìŠ¤ ë§ˆì¼“ í”¼ì²˜ (ìƒê´€ê´€ê³„ ë“±)
                df = self._add_cross_market_features(df, stock, target_date)
                
                # ì‹œì¥ ì²´ì œ í”¼ì²˜
                if self.market_condition:
                    df = self._add_market_regime_features(df)
                
                print(f"   âœ… í”¼ì²˜ ìƒì„± ì™„ë£Œ: {len(df)} í–‰, {len(df.columns)} í”¼ì²˜")
                return df
                
        except Exception as e:
            print(f"   âŒ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _build_feature_dataframe(self, price_data: List, stock: StockMaster) -> pd.DataFrame:
        """ê¸°ë³¸ í”¼ì²˜ DataFrame êµ¬ì„±"""
        
        # ê°€ê²© ë°ì´í„° ë³€í™˜ (ë‚ ì§œëŠ” ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜)
        price_df = pd.DataFrame([{
            'date_ordinal': p.trade_date.toordinal(),  # ë‚ ì§œë¥¼ ì„œìˆ˜(ì •ìˆ˜)ë¡œ ë³€í™˜
            'open': float(p.open_price),
            'high': float(p.high_price),
            'low': float(p.low_price),
            'close': float(p.close_price),
            'volume': int(p.volume) if p.volume else 0,
            'adjusted_close': float(p.adjusted_close_price) if p.adjusted_close_price else float(p.close_price),
            'daily_return': float(p.daily_return_pct) if p.daily_return_pct else 0.0,
            'vwap': float(p.vwap) if p.vwap else float(p.close_price)
        } for p in price_data])
        
        # ê¸°ë³¸ ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°
        price_df = price_df.sort_values('date_ordinal').reset_index(drop=True)
        
        # ì´ë™í‰ê· 
        price_df['sma_5'] = price_df['close'].rolling(5, min_periods=1).mean()
        price_df['sma_20'] = price_df['close'].rolling(20, min_periods=1).mean()
        price_df['sma_50'] = price_df['close'].rolling(50, min_periods=1).mean()
        
        # RSI
        delta = price_df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
        rs = gain / loss
        price_df['rsi_14'] = 100 - (100 / (1 + rs))
        
        # ë³¼ë¦°ì € ë°´ë“œ
        price_df['bb_middle'] = price_df['sma_20']
        bb_std = price_df['close'].rolling(20, min_periods=1).std()
        price_df['bb_upper'] = price_df['bb_middle'] + (bb_std * 2)
        price_df['bb_lower'] = price_df['bb_middle'] - (bb_std * 2)
        price_df['bb_percent'] = (price_df['close'] - price_df['bb_lower']) / (price_df['bb_upper'] - price_df['bb_lower'])
        
        # MACD
        ema_12 = price_df['close'].ewm(span=12).mean()
        ema_26 = price_df['close'].ewm(span=26).mean()
        price_df['macd'] = ema_12 - ema_26
        price_df['macd_signal'] = price_df['macd'].ewm(span=9).mean()
        
        # ê±°ë˜ëŸ‰ ë¹„ìœ¨
        price_df['volume_ratio'] = price_df['volume'] / price_df['volume'].rolling(20, min_periods=1).mean()
        
        # ê¸°ë³¸ í”¼ì²˜ ì¶”ê°€
        price_df['price_range'] = (price_df['high'] - price_df['low']) / price_df['close']
        price_df['open_close_ratio'] = price_df['open'] / price_df['close']
        price_df['high_close_ratio'] = price_df['high'] / price_df['close']
        price_df['low_close_ratio'] = price_df['low'] / price_df['close']
        price_df['volume_price_trend'] = price_df['volume'] * price_df['daily_return']
        
        return price_df.fillna(method='ffill').fillna(0)
    
    def _add_advanced_features(self, df: pd.DataFrame, stock: StockMaster) -> pd.DataFrame:
        """ê³ ê¸‰ í”¼ì²˜ ì¶”ê°€ - ë”¥ëŸ¬ë‹ ìŠ¤íƒ€ì¼"""
        
        # 1. ì‹œê³„ì—´ ìœˆë„ìš° í”¼ì²˜ (3, 5, 10, 20ì¼)
        for window in [3, 5, 10, 20]:
            # ê°€ê²© ëª¨ë©˜í…€
            df[f'price_momentum_{window}'] = df['close'].pct_change(window)
            
            # ë³€ë™ì„±
            df[f'volatility_{window}'] = df['daily_return'].rolling(window).std()
            
            # ê±°ë˜ëŸ‰ í‰ê· 
            df[f'volume_ma_{window}'] = df['volume'].rolling(window).mean()
            
            # ìµœê³ ê°€/ìµœì €ê°€ ëŒ€ë¹„ í˜„ì¬ ìœ„ì¹˜
            df[f'high_position_{window}'] = (df['close'] - df['low'].rolling(window).min()) / (
                df['high'].rolling(window).max() - df['low'].rolling(window).min()
            )
        
        # 2. ê¸°ìˆ ì  ë¶„ì„ ê³ ê¸‰ í”¼ì²˜
        # RSI ê¸°ë°˜ í”¼ì²˜
        df['rsi_ma_5'] = df['rsi_14'].rolling(5).mean()
        df['rsi_divergence'] = df['rsi_14'] - df['rsi_ma_5']
        df['rsi_extreme'] = ((df['rsi_14'] > 70) | (df['rsi_14'] < 30)).astype(int)
        
        # ë³¼ë¦°ì € ë°´ë“œ ê¸°ë°˜ í”¼ì²˜
        df['bb_squeeze'] = (df['bb_upper'] - df['bb_lower']) / df['close']
        df['bb_position'] = df['bb_percent']
        df['bb_breakout'] = ((df['close'] > df['bb_upper']) | (df['close'] < df['bb_lower'])).astype(int)
        
        # 3. ê°€ê²© íŒ¨í„´ í”¼ì²˜
        # ê°­ ë¶„ì„
        df['gap_up'] = ((df['open'] > df['close'].shift(1)) & 
                       (df['open'] - df['close'].shift(1)) / df['close'].shift(1) > 0.02).astype(int)
        df['gap_down'] = ((df['open'] < df['close'].shift(1)) & 
                         (df['close'].shift(1) - df['open']) / df['close'].shift(1) > 0.02).astype(int)
        
        # ìº”ë“¤ìŠ¤í‹± íŒ¨í„´ (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        price_range = df['high'] - df['low']
        price_range = price_range.where(price_range > 0, 0.001)  # 0ì´ë©´ 0.001ë¡œ ëŒ€ì²´
        df['doji'] = (abs(df['open'] - df['close']) / price_range < 0.1).astype(int)
        df['hammer'] = ((df['close'] > df['open']) & 
                       ((df['open'] - df['low']) > 2 * (df['close'] - df['open']))).astype(int)
        
        # 4. ë§ˆì¼“ ë§ˆì´í¬ë¡œìŠ¤íŠ¸ëŸ­ì²˜ í”¼ì²˜
        # ê±°ë˜ëŸ‰ í”„ë¡œíŒŒì¼
        df['volume_surge'] = (df['volume'] > df['volume'].rolling(20).mean() * 2).astype(int)
        df['volume_dry'] = (df['volume'] < df['volume'].rolling(20).mean() * 0.5).astype(int)
        
        # ê°€ê²©-ê±°ë˜ëŸ‰ ìƒê´€ê´€ê³„
        df['price_volume_corr'] = df['daily_return'].rolling(20).corr(df['volume'].pct_change())
        
        return df.fillna(0)
    
    def _add_cross_market_features(self, df: pd.DataFrame, stock: StockMaster, target_date: date) -> pd.DataFrame:
        """í¬ë¡œìŠ¤ ë§ˆì¼“ í”¼ì²˜ ì¶”ê°€"""
        
        try:
            # ìƒëŒ€ ì‹œì¥ ì •ë³´
            other_region = MarketRegion.US if stock.market_region == MarketRegion.KR.value else MarketRegion.KR
            
            with get_db_session() as db:
                # ë‹¤ë¥¸ ì‹œì¥ì˜ ëŒ€í‘œ ì§€ìˆ˜ ë°ì´í„°
                other_market_data = self._get_market_index_data(
                    db, other_region, 
                    target_date - timedelta(days=60), 
                    target_date
                )
                
                if other_market_data:
                    # ë‹¤ë¥¸ ì‹œì¥ ìˆ˜ìµë¥  ê³„ì‚°
                    other_returns = pd.Series(other_market_data).pct_change().fillna(0)
                    
                    # ìµœê·¼ ìƒê´€ê´€ê³„
                    if len(other_returns) >= len(df['daily_return']):
                        recent_other = other_returns.tail(len(df))
                        df['cross_market_corr'] = df['daily_return'].rolling(20).corr(recent_other)
                    
                    # ë‹¤ë¥¸ ì‹œì¥ íŠ¸ë Œë“œ ì˜í–¥
                    if len(other_returns) > 0:
                        other_trend = other_returns.tail(5).mean()
                        df['other_market_trend'] = other_trend
                        df['cross_market_momentum'] = df['daily_return'] * other_trend
                
        except Exception as e:
            print(f"   âš ï¸ í¬ë¡œìŠ¤ ë§ˆì¼“ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return df.fillna(0)
    
    def _add_market_regime_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì‹œì¥ ì²´ì œ í”¼ì²˜ ì¶”ê°€"""
        
        if not self.market_condition:
            return df
        
        # ì‹œì¥ ì²´ì œ ë”ë¯¸ ë³€ìˆ˜
        for regime in MarketRegime:
            df[f'regime_{regime.value}'] = (self.market_condition.regime == regime).astype(int)
        
        # ì‹œì¥ ì¡°ê±´ í”¼ì²˜
        df['market_volatility'] = self.market_condition.volatility_level
        df['market_correlation'] = self.market_condition.correlation_kr_us
        df['market_fear_greed'] = self.market_condition.fear_greed_index
        df['market_trend_strength'] = self.market_condition.trend_strength
        
        # ë¦¬ìŠ¤í¬ ë ˆë²¨ ë”ë¯¸ ë³€ìˆ˜
        for risk in ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL']:
            df[f'risk_{risk.lower()}'] = (self.market_condition.risk_level == risk).astype(int)
        
        return df
    
    def train_global_models(self, use_intensive_config: bool = False) -> bool:
        """ê¸€ë¡œë²Œ ML ëª¨ë¸ í•™ìŠµ - ë°°í¬ í™˜ê²½ ìµœì í™”"""
        print("ğŸ‹ï¸ ê¸€ë¡œë²Œ ML ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        try:
            # ë°°í¬ í™˜ê²½ ê°ì§€
            is_production = Path("/volume1/project/stock-analyzer").exists()
            
            if is_production:
                print("ğŸš€ ë°°í¬ í™˜ê²½ ê°ì§€ - ê³ ì„±ëŠ¥ í•™ìŠµ ëª¨ë“œ")
                # ë°°í¬ í™˜ê²½ì—ì„œëŠ” ìµœëŒ€ ì„±ëŠ¥ìœ¼ë¡œ í•™ìŠµ
                model_config = {
                    'n_estimators': 300,        # íŠ¸ë¦¬ ê°œìˆ˜ ì¦ê°€
                    'max_depth': 12,            # ê¹Šì´ ì¦ê°€
                    'min_samples_split': 5,     # ë” ì„¸ë°€í•œ ë¶„í• 
                    'min_samples_leaf': 2,      # ë¦¬í”„ ë…¸ë“œ ìµœì†Œê°’
                    'max_features': 'sqrt',     # ëª¨ë“  í”¼ì²˜ ì‚¬ìš©
                    'random_state': 42,
                    'n_jobs': -1,              # ëª¨ë“  CPU ì½”ì–´ í™œìš©
                    'verbose': 1               # ì§„í–‰ìƒí™© í‘œì‹œ
                }
                
                if use_intensive_config or hasattr(self, 'model_config'):
                    # ì§‘ì¤‘ í•™ìŠµ ëª¨ë“œ
                    intensive_config = getattr(self, 'model_config', {})
                    if intensive_config:
                        model_config.update(intensive_config)
                        print(f"ğŸ”¥ ì§‘ì¤‘ í•™ìŠµ ì„¤ì • ì ìš©: {intensive_config}")
            else:
                print("ğŸ› ï¸ ê°œë°œ í™˜ê²½ - ë¹ ë¥¸ í•™ìŠµ ëª¨ë“œ")
                # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë¹ ë¥¸ í•™ìŠµ
                model_config = {
                    'n_estimators': 50,
                    'max_depth': 8,
                    'min_samples_split': 10,
                    'random_state': 42,
                    'n_jobs': 2
                }
            
            print(f"âš™ï¸ ëª¨ë¸ ì„¤ì •: {model_config}")
            
            # 1. ë°ì´í„° ì¤€ë¹„
            print("ğŸ“Š í•™ìŠµ ë°ì´í„° ì¤€ë¹„...")
            training_success = self._prepare_training_data()
            
            if not training_success:
                print("âŒ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨")
                return False
            
            # 2. í•œêµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ
            print("ğŸ‡°ğŸ‡· í•œêµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
            kr_success = self._train_market_model(MarketRegion.KR, model_config)
            
            # 3. ë¯¸êµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ
            print("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
            us_success = self._train_market_model(MarketRegion.US, model_config)
            
            # 4. ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
            print("ğŸŒ ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ...")
            ensemble_success = self._train_ensemble_model(model_config)
            
            success = kr_success and us_success and ensemble_success
            
            if success:
                if is_production:
                    print("ğŸ‰ ë°°í¬ í™˜ê²½ ê³ ì„±ëŠ¥ í•™ìŠµ ì™„ë£Œ!")
                else:
                    print("âœ… ê°œë°œ í™˜ê²½ í•™ìŠµ ì™„ë£Œ")
                
                # ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦
                self._validate_trained_models()
            else:
                print("âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
            
            return success
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def _prepare_training_data(self) -> bool:
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ë° ê²€ì¦"""
        print("ğŸ” í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        try:
            with get_db_session() as db:
                # í•œêµ­ ì‹œì¥ ë°ì´í„° í™•ì¸
                kr_stocks = db.query(StockMaster).filter_by(
                    market_region=MarketRegion.KR.value,
                    is_active=True
                ).count()
                
                # ë¯¸êµ­ ì‹œì¥ ë°ì´í„° í™•ì¸
                us_stocks = db.query(StockMaster).filter_by(
                    market_region=MarketRegion.US.value,
                    is_active=True
                ).count()
                
                # ìµœê·¼ ë°ì´í„° í™•ì¸
                recent_date = datetime.now().date() - timedelta(days=7)
                
                kr_recent_data = db.query(StockDailyPrice).join(StockMaster).filter(
                    StockMaster.market_region == MarketRegion.KR.value,
                    StockDailyPrice.trade_date >= recent_date
                ).count()
                
                us_recent_data = db.query(StockDailyPrice).join(StockMaster).filter(
                    StockMaster.market_region == MarketRegion.US.value,
                    StockDailyPrice.trade_date >= recent_date
                ).count()
                
                print(f"   ğŸ‡°ğŸ‡· í•œêµ­ ì¢…ëª©: {kr_stocks}ê°œ, ìµœê·¼ ë°ì´í„°: {kr_recent_data}ê°œ")
                print(f"   ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì¢…ëª©: {us_stocks}ê°œ, ìµœê·¼ ë°ì´í„°: {us_recent_data}ê°œ")
                
                # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ê²€ì¦
                if kr_stocks < 10 or us_stocks < 10:
                    print("   âŒ ì¢…ëª© ë°ì´í„° ë¶€ì¡±")
                    return False
                
                if kr_recent_data < 50 or us_recent_data < 50:
                    print("   âŒ ìµœê·¼ ê°€ê²© ë°ì´í„° ë¶€ì¡±")
                    return False
                
                print("   âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
                return True
                
        except Exception as e:
            print(f"   âŒ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return False
    
    def train_global_models_intensive(self, use_intensive_config: bool = True) -> bool:
        """ì§‘ì¤‘ í•™ìŠµ ëª¨ë“œ - ì¤‘ë³µ ì œê±°ë¨"""
        print("ï¿½ ì§‘ì¤‘ í•™ìŠµ ëª¨ë“œ...")
        
        try:
            # ì§‘ì¤‘ í•™ìŠµ ì„¤ì •
            intensive_config = {
                'n_estimators': 500,
                'max_depth': 15,
                'min_samples_split': 5,
                'min_samples_leaf': 2,
                'max_features': 'sqrt',
                'random_state': 42,
                'n_jobs': -1,
                'verbose': 1
            }
            
            print(f"âš™ï¸ ì§‘ì¤‘ í•™ìŠµ ì„¤ì •: {intensive_config}")
            
            # 1. ë°ì´í„° ì¤€ë¹„
            print("ğŸ“Š í•™ìŠµ ë°ì´í„° ì¤€ë¹„...")
            training_success = self._prepare_training_data()
            
            if not training_success:
                print("âŒ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨")
                return False
            
            # 2. í•œêµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ
            print("ğŸ‡°ğŸ‡· í•œêµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
            kr_success = self._train_market_model(MarketRegion.KR, intensive_config)
            
            # 3. ë¯¸êµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ
            print("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
            us_success = self._train_market_model(MarketRegion.US, intensive_config)
            
            # 4. ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
            print("ğŸŒ ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ...")
            ensemble_success = self._train_ensemble_model(intensive_config)
            
            success = kr_success and us_success and ensemble_success
            
            if success:
                print("ğŸ‰ ì§‘ì¤‘ í•™ìŠµ ì™„ë£Œ!")
                # ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦
                self._validate_trained_models()
            else:
                print("âŒ ì§‘ì¤‘ í•™ìŠµ ì‹¤íŒ¨")
            
            return success
            
        except Exception as e:
            print(f"âŒ ì§‘ì¤‘ í•™ìŠµ ì˜¤ë¥˜: {e}")
            return False
    
    def _validate_trained_models(self):
        """í•™ìŠµëœ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦ - ê²½ë¡œ í†µì¼"""
        try:
            print("ğŸ” í•™ìŠµëœ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦...")
            
            # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸ (ì‹¤ì œ ì €ì¥ í˜•ì‹ì— ë§ì¶¤)
            required_models = [
                f"KR_model_{self.model_version}.joblib",
                f"KR_scaler_{self.model_version}.joblib",
                f"US_model_{self.model_version}.joblib", 
                f"US_scaler_{self.model_version}.joblib",
                f"ensemble_model_{self.model_version}.joblib",
                f"ensemble_scaler_{self.model_version}.joblib"
            ]
            
            model_status = {}
            for model_name in required_models:
                model_path = self.model_dir / model_name  # self.model_dir ì‚¬ìš©
                if model_path.exists():
                    model_status[model_name] = "âœ… ì¡´ì¬"
                    # íŒŒì¼ í¬ê¸° í™•ì¸
                    size_mb = model_path.stat().st_size / (1024 * 1024)
                    model_status[model_name] += f" ({size_mb:.1f}MB)"
                else:
                    model_status[model_name] = "âŒ ì—†ìŒ"
            
            print("ğŸ“‹ ëª¨ë¸ íŒŒì¼ ìƒíƒœ:")
            for model, status in model_status.items():
                print(f"   â€¢ {model}: {status}")
            
            # ëª¨ë“  ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            all_exist = all("âœ…" in status for status in model_status.values())
            if all_exist:
                print("âœ… ëª¨ë“  ëª¨ë¸ íŒŒì¼ ê²€ì¦ ì™„ë£Œ")
            else:
                print("âš ï¸ ì¼ë¶€ ëª¨ë¸ íŒŒì¼ ëˆ„ë½")
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    def _train_market_model(self, region: MarketRegion, model_config: dict = None) -> bool:
        """ì‹œì¥ë³„ ëª¨ë¸ í•™ìŠµ"""
        print(f"ğŸ¯ {region.value} ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
        
        if model_config is None:
            model_config = {
                'n_estimators': 100,
                'max_depth': 10,
                'random_state': 42,
                'n_jobs': -1
            }
        
        try:
            with get_db_session() as db:
                # í•´ë‹¹ ì‹œì¥ ì¢…ëª© ëª©ë¡
                stocks = db.query(StockMaster).filter_by(
                    market_region=region.value,
                    is_active=True
                ).all()
                
                all_features = []
                all_targets = []
                sample_weights = []  # ê°€ì¤‘ì¹˜ ì¶”ê°€
                
                for stock in stocks[:20]:  # ìƒìœ„ 20ê°œ ì¢…ëª©ìœ¼ë¡œ ì œí•œ
                    print(f"   ğŸ“Š {stock.stock_code} ë°ì´í„° ìˆ˜ì§‘...")
                    
                    # ìµœê·¼ 180ì¼ ë°ì´í„°
                    end_date = datetime.now().date()
                    
                    for days_back in range(30, 150):  # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
                        current_date = end_date - timedelta(days=days_back)
                        
                        # í”¼ì²˜ ìƒì„±
                        features = self.prepare_global_features(stock.stock_id, current_date)
                        
                        if features is None or len(features) < 30:
                            continue
                        
                        # íƒ€ê²Ÿ ìƒì„± (5ì¼ í›„ ìˆ˜ìµë¥ )
                        future_date = current_date + timedelta(days=5)
                        target = self._get_future_return(db, stock.stock_id, current_date, future_date)
                        
                        if target is None:
                            continue
                        
                        # ìµœì‹  ë°ì´í„° ì‚¬ìš©
                        latest_features = features.iloc[-1].fillna(0)
                        
                        # ê°€ì¤‘ì¹˜ ê³„ì‚° (ìµœì‹  ë°ì´í„°ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
                        time_weight = 1.0 / (days_back / 30.0 + 1.0)  # ì‹œê°„ ê°€ì¤‘ì¹˜
                        
                        # ë³€ë™ì„± ê°€ì¤‘ì¹˜ (ë†’ì€ ë³€ë™ì„±ì€ ë‚®ì€ ê°€ì¤‘ì¹˜)
                        volatility = features['volatility_20'].iloc[-1] if 'volatility_20' in features.columns else 0.02
                        volatility_weight = 1.0 / (volatility * 50 + 1.0)
                        
                        # ê±°ë˜ëŸ‰ ê°€ì¤‘ì¹˜ (ë†’ì€ ê±°ë˜ëŸ‰ì€ ë†’ì€ ê°€ì¤‘ì¹˜)
                        volume_ratio = features.get('volume_ratio', pd.Series([1.0])).iloc[-1]
                        volume_weight = min(volume_ratio / 2.0 + 0.5, 2.0)
                        
                        # ìµœì¢… ê°€ì¤‘ì¹˜
                        final_weight = time_weight * volatility_weight * volume_weight
                        
                        all_features.append(latest_features)
                        all_targets.append(target)
                        sample_weights.append(final_weight)
                
                if len(all_features) < 50:
                    print(f"   âš ï¸ {region.value}: í•™ìŠµ ë°ì´í„° ë¶€ì¡± ({len(all_features)}ê°œ)")
                    return False
                
                # DataFrame ë³€í™˜
                X = pd.DataFrame(all_features)
                y = np.array(all_targets)
                weights = np.array(sample_weights)
                
                print(f"   ğŸ“ˆ í•™ìŠµ ë°ì´í„°: {len(X)}ê°œ ìƒ˜í”Œ, {len(X.columns)}ê°œ í”¼ì²˜")
                print(f"   âš–ï¸ ê°€ì¤‘ì¹˜ ë²”ìœ„: {weights.min():.3f} - {weights.max():.3f}")
                
                # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
                scaler = RobustScaler()  # ì•„ì›ƒë¼ì´ì–´ì— ê°•ê±´í•œ ìŠ¤ì¼€ì¼ëŸ¬
                X_scaled = scaler.fit_transform(X)
                
                # ì•™ìƒë¸” ëª¨ë¸ ìƒì„± (ê°€ì¤‘ì¹˜ ì ìš©)
                rf_model = RandomForestRegressor(**model_config)
                gb_model = GradientBoostingRegressor(
                    n_estimators=model_config.get('n_estimators', 100),
                    max_depth=model_config.get('max_depth', 10),
                    random_state=model_config.get('random_state', 42)
                )
                
                ensemble_model = VotingRegressor([
                    ('rf', rf_model),
                    ('gb', gb_model)
                ])
                
                # ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ëª¨ë¸ í•™ìŠµ
                print(f"   ğŸ‹ï¸ ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ í•™ìŠµ ì¤‘...")
                ensemble_model.fit(X_scaled, y, sample_weight=weights)
                
                # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
                y_pred = ensemble_model.predict(X_scaled)
                mse = mean_squared_error(y, y_pred, sample_weight=weights)
                r2 = r2_score(y, y_pred, sample_weight=weights)
                
                print(f"   ğŸ“Š ì„±ëŠ¥ ì§€í‘œ - MSE: {mse:.4f}, RÂ²: {r2:.4f}")
                
                # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
                if hasattr(ensemble_model.estimators_[0], 'feature_importances_'):
                    feature_importance = ensemble_model.estimators_[0].feature_importances_
                    top_features = pd.Series(feature_importance, index=X.columns).nlargest(10)
                    print(f"   ğŸ¯ ì£¼ìš” í”¼ì²˜:")
                    for feature, importance in top_features.items():
                        print(f"      {feature}: {importance:.3f}")
                
                # ëª¨ë¸ ì €ì¥ - ë„¤ì´ë° í†µì¼
                self.models[f"{region.value}_ensemble"] = ensemble_model
                self.scalers[f"{region.value}_ensemble"] = scaler
                
                model_path = self.model_dir / f"ensemble_model_{self.model_version}.joblib"
                scaler_path = self.model_dir / f"ensemble_scaler_{self.model_version}.joblib"
                
                joblib.dump(ensemble_model, model_path)
                joblib.dump(scaler, scaler_path)
                
                print(f"   âœ… ì•™ìƒë¸” ëª¨ë¸ ì €ì¥: {model_path}")
                return True
                
                print(f"   ğŸ“ˆ í•™ìŠµ ë°ì´í„°: {len(X)}ê°œ ìƒ˜í”Œ, {len(X.columns)}ê°œ í”¼ì²˜")
                
                # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
                scaler = RobustScaler()
                X_scaled = scaler.fit_transform(X)
                
                # ëª¨ë¸ ì •ì˜ (ì•™ìƒë¸”)
                models = {
                    'rf': RandomForestRegressor(
                        n_estimators=200,
                        max_depth=15,
                        min_samples_split=10,
                        min_samples_leaf=5,
                        random_state=42,
                        n_jobs=-1
                    ),
                    'gbm': GradientBoostingRegressor(
                        n_estimators=150,
                        max_depth=8,
                        learning_rate=0.1,
                        subsample=0.8,
                        random_state=42
                    ),
                    'ridge': Ridge(alpha=1.0, random_state=42)
                }
                
                # ê°œë³„ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
                model_scores = {}
                trained_models = {}
                
                tscv = TimeSeriesSplit(n_splits=5)
                
                for name, model in models.items():
                    print(f"   ğŸ”§ {name} ëª¨ë¸ í•™ìŠµ...")
                    
                    # êµì°¨ ê²€ì¦
                    cv_scores = cross_val_score(model, X_scaled, y, cv=tscv, scoring='neg_mean_squared_error')
                    mse_score = -cv_scores.mean()
                    
                    # ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ
                    model.fit(X_scaled, y)
                    
                    model_scores[name] = mse_score
                    trained_models[name] = model
                    
                    print(f"      MSE: {mse_score:.6f}")
                
                # ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
                best_models = sorted(model_scores.items(), key=lambda x: x[1])[:2]  # ìƒìœ„ 2ê°œ
                ensemble_models = [(name, trained_models[name]) for name, _ in best_models]
                
                ensemble = VotingRegressor(estimators=ensemble_models)
                ensemble.fit(X_scaled, y)
                
                # ìµœì¢… í‰ê°€
                ensemble_score = -cross_val_score(ensemble, X_scaled, y, cv=tscv, scoring='neg_mean_squared_error').mean()
                print(f"   ğŸ¯ ì•™ìƒë¸” MSE: {ensemble_score:.6f}")
                
                # ëª¨ë¸ ì €ì¥
                model_path = self.model_dir / f"{region.value}_model_{self.model_version}.joblib"
                scaler_path = self.model_dir / f"{region.value}_scaler_{self.model_version}.joblib"
                
                joblib.dump(ensemble, model_path)
                joblib.dump(scaler, scaler_path)
                
                # ë©”ëª¨ë¦¬ì— ì €ì¥
                self.models[region.value] = ensemble
                self.scalers[region.value] = scaler
                
                print(f"   âœ… {region.value} ëª¨ë¸ ì €ì¥: {model_path}")
                return True
                
        except Exception as e:
            print(f"   âŒ {region.value} ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return False
    
    def _get_future_return(self, db, stock_id: int, current_date: date, future_date: date) -> Optional[float]:
        """ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°"""
        try:
            current_price = db.query(StockDailyPrice).filter(
                StockDailyPrice.stock_id == stock_id,
                StockDailyPrice.trade_date == current_date
            ).first()
            
            future_price = db.query(StockDailyPrice).filter(
                StockDailyPrice.stock_id == stock_id,
                StockDailyPrice.trade_date >= future_date,
                StockDailyPrice.trade_date <= future_date + timedelta(days=7)
            ).first()
            
            if current_price and future_price:
                return_pct = (float(future_price.close_price) - float(current_price.close_price)) / float(current_price.close_price) * 100
                return return_pct
            
            return None
            
        except Exception:
            return None
    
    def _train_ensemble_model(self, model_config: dict = None) -> bool:
        """ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ - í•œêµ­ê³¼ ë¯¸êµ­ ëª¨ë¸ì„ ê²°í•©"""
        print("ğŸŒ ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ...")
        
        try:
            # í•œêµ­ê³¼ ë¯¸êµ­ ëª¨ë¸ì´ ëª¨ë‘ í•™ìŠµë˜ì—ˆëŠ”ì§€ í™•ì¸
            if MarketRegion.KR.value not in self.models or MarketRegion.US.value not in self.models:
                print("   âš ï¸ ê¸°ë³¸ ì‹œì¥ ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•ŠìŒ")
                return False
            
            # ì•™ìƒë¸”ì„ ìœ„í•œ ê¸€ë¡œë²Œ ë°ì´í„° ìˆ˜ì§‘
            with get_db_session() as db:
                # í•œêµ­ + ë¯¸êµ­ ëŒ€í‘œ ì¢…ëª©ë“¤ë¡œ ê¸€ë¡œë²Œ ë°ì´í„°ì…‹ êµ¬ì„±
                kr_stocks = db.query(StockMaster).filter_by(
                    market_region=MarketRegion.KR.value,
                    is_active=True
                ).limit(10).all()
                
                us_stocks = db.query(StockMaster).filter_by(
                    market_region=MarketRegion.US.value,
                    is_active=True
                ).limit(10).all()
                
                all_features = []
                all_targets = []
                all_regions = []
                
                # í•œêµ­ ë°ì´í„°
                for stock in kr_stocks:
                    features, targets = self._collect_stock_data_for_ensemble(db, stock, MarketRegion.KR)
                    if features is not None and len(features) > 0:
                        all_features.extend(features)
                        all_targets.extend(targets)
                        all_regions.extend([MarketRegion.KR.value] * len(features))
                
                # ë¯¸êµ­ ë°ì´í„°
                for stock in us_stocks:
                    features, targets = self._collect_stock_data_for_ensemble(db, stock, MarketRegion.US)
                    if features is not None and len(features) > 0:
                        all_features.extend(features)
                        all_targets.extend(targets)
                        all_regions.extend([MarketRegion.US.value] * len(features))
                
                if len(all_features) < 100:
                    print(f"   âš ï¸ ì•™ìƒë¸” í•™ìŠµ ë°ì´í„° ë¶€ì¡±: {len(all_features)}ê°œ")
                    return False
                
                # ê¸€ë¡œë²Œ í”¼ì²˜ DataFrame ìƒì„±
                X_global = pd.DataFrame(all_features)
                y_global = np.array(all_targets)
                regions = np.array(all_regions)
                
                print(f"   ğŸ“ˆ ì•™ìƒë¸” ë°ì´í„°: {len(X_global)}ê°œ ìƒ˜í”Œ, {len(X_global.columns)}ê°œ í”¼ì²˜")
                
                # ì§€ì—­ë³„ ê°€ì¤‘ì¹˜ ì ìš© (ê· í˜• ì¡°ì •)
                kr_weight = 1.0 / np.sum(regions == MarketRegion.KR.value)
                us_weight = 1.0 / np.sum(regions == MarketRegion.US.value)
                
                sample_weights = np.where(regions == MarketRegion.KR.value, kr_weight, us_weight)
                sample_weights = sample_weights / sample_weights.sum() * len(sample_weights)  # ì •ê·œí™”
                
                # ê¸€ë¡œë²Œ ìŠ¤ì¼€ì¼ëŸ¬
                global_scaler = RobustScaler()
                X_scaled = global_scaler.fit_transform(X_global)
                
                # ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ ì •ì˜
                global_ensemble = VotingRegressor([
                    ('rf_global', RandomForestRegressor(
                        n_estimators=model_config.get('n_estimators', 200),
                        max_depth=model_config.get('max_depth', 12),
                        min_samples_split=5,
                        min_samples_leaf=2,
                        random_state=42,
                        n_jobs=-1
                    )),
                    ('gb_global', GradientBoostingRegressor(
                        n_estimators=150,
                        max_depth=8,
                        learning_rate=0.08,
                        subsample=0.8,
                        random_state=42
                    )),
                    ('ridge_global', Ridge(alpha=1.0, random_state=42))
                ])
                
                # ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
                print("   ğŸ‹ï¸ ê¸€ë¡œë²Œ ì•™ìƒë¸” í•™ìŠµ ì¤‘...")
                global_ensemble.fit(X_scaled, y_global, sample_weight=sample_weights)
                
                # ì„±ëŠ¥ í‰ê°€
                y_pred = global_ensemble.predict(X_scaled)
                mse = mean_squared_error(y_global, y_pred, sample_weight=sample_weights)
                r2 = r2_score(y_global, y_pred, sample_weight=sample_weights)
                
                print(f"   ğŸ“Š ê¸€ë¡œë²Œ ì•™ìƒë¸” ì„±ëŠ¥ - MSE: {mse:.4f}, RÂ²: {r2:.4f}")
                
                # ëª¨ë¸ ì €ì¥
                self.models['global_ensemble'] = global_ensemble
                self.scalers['global_ensemble'] = global_scaler
                
                ensemble_path = self.model_dir / "global_ensemble_model.joblib"
                ensemble_scaler_path = self.model_dir / "global_ensemble_scaler.joblib"
                
                joblib.dump(global_ensemble, ensemble_path)
                joblib.dump(global_scaler, ensemble_scaler_path)
                
                print("   âœ… ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
                return True
                
        except Exception as e:
            print(f"   âŒ ê¸€ë¡œë²Œ ì•™ìƒë¸” í•™ìŠµ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def _collect_stock_data_for_ensemble(self, db, stock: StockMaster, region: MarketRegion) -> Tuple[List, List]:
        """ì•™ìƒë¸”ìš© ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            features_list = []
            targets_list = []
            
            # ìµœê·¼ 60ì¼ê°„ ë°ì´í„° ìˆ˜ì§‘
            end_date = datetime.now().date()
            
            for days_back in range(30, 90, 2):  # 2ì¼ ê°„ê²©ìœ¼ë¡œ ìƒ˜í”Œë§
                current_date = end_date - timedelta(days=days_back)
                
                # í”¼ì²˜ ìƒì„±
                features = self.prepare_global_features(stock.stock_id, current_date)
                if features is None or len(features) < 30:
                    continue
                
                # ë¯¸ë˜ ìˆ˜ìµë¥  (íƒ€ê²Ÿ)
                future_date = current_date + timedelta(days=5)
                target = self._get_future_return(db, stock.stock_id, current_date, future_date)
                
                if target is None:
                    continue
                
                # ìµœì‹  í”¼ì²˜ ë°ì´í„°
                latest_features = features.iloc[-1].fillna(0).to_dict()
                
                # ì§€ì—­ ì •ë³´ ì¶”ê°€
                latest_features['is_kr'] = 1.0 if region == MarketRegion.KR else 0.0
                latest_features['is_us'] = 1.0 if region == MarketRegion.US else 0.0
                
                features_list.append(latest_features)
                targets_list.append(target)
            
            return features_list, targets_list
            
        except Exception as e:
            print(f"   âš ï¸ {stock.stock_code} ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return [], []
    
    def predict_stocks(self, region: MarketRegion, top_n: int = 5) -> List[GlobalPrediction]:
        """ì£¼ì‹ ì˜ˆì¸¡ ì‹¤í–‰ - ëª¨ë¸ ì—†ìœ¼ë©´ ìë™ í•™ìŠµ"""
        print(f"ğŸ¯ {region.value} ì£¼ì‹ ì˜ˆì¸¡ ì¤‘... (ìƒìœ„ {top_n}ê°œ)")
        
        predictions = []
        
        try:
            # ëª¨ë¸ ë¡œë“œ
            if region.value not in self.models:
                self._load_model(region)
            
            # ëª¨ë¸ì´ ì—¬ì „íˆ ì—†ìœ¼ë©´ ìë™ í•™ìŠµ ìˆ˜í–‰
            if region.value not in self.models:
                print(f"   âš ï¸ {region.value} ëª¨ë¸ ì—†ìŒ - ìë™ í•™ìŠµ ì‹œì‘...")
                
                # ê¸´ê¸‰ í•™ìŠµ ìˆ˜í–‰
                try:
                    print(f"   ğŸš€ {region.value} ê¸´ê¸‰ ML ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
                    success = self._train_market_model(region, {
                        'n_estimators': 100,  # ë¹ ë¥¸ í•™ìŠµìš©
                        'max_depth': 10,
                        'random_state': 42,
                        'n_jobs': -1
                    })
                    
                    if success:
                        print(f"   âœ… {region.value} ê¸´ê¸‰ í•™ìŠµ ì™„ë£Œ")
                    else:
                        print(f"   âŒ {region.value} ê¸´ê¸‰ í•™ìŠµ ì‹¤íŒ¨")
                        return []
                        
                except Exception as e:
                    print(f"   âŒ {region.value} ê¸´ê¸‰ í•™ìŠµ ì˜¤ë¥˜: {e}")
                    return []
            
            # ëª¨ë¸ ìµœì¢… í™•ì¸
            if region.value not in self.models:
                print(f"   âŒ {region.value} ëª¨ë¸ ì—¬ì „íˆ ì—†ìŒ")
                return []

            model = self.models[region.value]
            scaler = self.scalers[region.value]
            
            with get_db_session() as db:
                # ì¢…ëª© ëª©ë¡
                stocks = db.query(StockMaster).filter_by(
                    market_region=region.value,
                    is_active=True
                ).all()
                
                # í˜„ì¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì ì ˆí•œ ë‚ ì§œ ê²°ì •
                now = datetime.now()
                current_time = now.time()
                
                # ì‹œì¥ë³„ ë°ì´í„° ê°€ìš© ì‹œê°„ ê¸°ì¤€
                if region == MarketRegion.KR:
                    # í•œêµ­ ì‹œì¥: 16:00(ì¥ ë§ˆê°) ì´í›„ë©´ ë‹¹ì¼ ë°ì´í„° ì‚¬ìš©
                    if current_time.hour >= 16:
                        target_date = now.date()  # ë‹¹ì¼ ë°ì´í„°
                    else:
                        target_date = now.date() - timedelta(days=1)  # ì „ì¼ ë°ì´í„°
                else:
                    # ë¯¸êµ­ ì‹œì¥: 05:30(í•œêµ­ì‹œê°„ ì¥ ë§ˆê° í›„) ~ 17:00 ì‚¬ì´ë©´ ë‹¹ì¼ ë°ì´í„°
                    hour = current_time.hour
                    minute = current_time.minute
                    
                    if (hour == 5 and minute >= 30) or (6 <= hour <= 16):
                        target_date = now.date()  # ë‹¹ì¼ ë°ì´í„°
                    else:
                        target_date = now.date() - timedelta(days=1)  # ì „ì¼ ë°ì´í„°
                
                print(f"ğŸ—“ï¸ {region.value} ì˜ˆì¸¡ ê¸°ì¤€ì¼: {target_date} ({'ë‹¹ì¼' if target_date == now.date() else 'ì „ì¼'} ë°ì´í„°)")
                
                for stock in stocks:
                    try:
                        # í”¼ì²˜ ìƒì„±
                        features = self.prepare_global_features(stock.stock_id, target_date)
                        
                        if features is None or len(features) == 0:
                            continue
                        
                        # ì˜ˆì¸¡ ì‹¤í–‰
                        latest_features = features.iloc[-1].fillna(0)
                        X_scaled = scaler.transform([latest_features])
                        
                        predicted_return = model.predict(X_scaled)[0]
                        
                        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (ê°„ì†Œí™”)
                        confidence = self._calculate_confidence(features, predicted_return)
                        
                        # ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°
                        risk_score = self._calculate_risk_score(features, predicted_return)
                        
                        # ì¶”ì²œ ë“±ê¸‰ ê²°ì •
                        recommendation = self._determine_recommendation(predicted_return, confidence, risk_score)
                        
                        # ëª©í‘œê°€/ì†ì ˆê°€ ê³„ì‚°
                        current_price = float(features['close'].iloc[-1])
                        target_price = current_price * (1 + predicted_return / 100)
                        stop_loss = current_price * 0.95  # 5% ì†ì ˆ
                        
                        # ì¶”ë¡  ì´ìœ 
                        reasoning = self._generate_reasoning(features, predicted_return, stock)
                        
                        prediction = GlobalPrediction(
                            stock_code=stock.stock_code,
                            market_region=region.value,
                            predicted_return=predicted_return,
                            confidence_score=confidence,
                            risk_score=risk_score,
                            recommendation=recommendation,
                            target_price=target_price,
                            stop_loss=stop_loss,
                            reasoning=reasoning
                        )
                        
                        predictions.append(prediction)
                        
                    except Exception as e:
                        print(f"   âš ï¸ {stock.stock_code}: {e}")
                        continue
                
            # ìˆ˜ìµë¥  ê¸°ì¤€ ì •ë ¬
            predictions.sort(key=lambda x: x.predicted_return, reverse=True)
            
            print(f"   âœ… {len(predictions)}ê°œ ì¢…ëª© ì˜ˆì¸¡ ì™„ë£Œ")
            return predictions[:top_n]
            
        except Exception as e:
            print(f"   âŒ {region.value} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return []
    
    def _load_model(self, region: MarketRegion):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            model_path = self.model_dir / f"{region.value}_model_{self.model_version}.joblib"
            scaler_path = self.model_dir / f"{region.value}_scaler_{self.model_version}.joblib"
            
            if model_path.exists() and scaler_path.exists():
                self.models[region.value] = joblib.load(model_path)
                self.scalers[region.value] = joblib.load(scaler_path)
                print(f"   âœ… {region.value} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"   âš ï¸ {region.value} ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
                
        except Exception as e:
            print(f"   âŒ {region.value} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _calculate_confidence(self, features: pd.DataFrame, predicted_return: float) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ì‹œì¥ ì¡°ê±´ì— ë”°ë¥¸ ì‹ ë¢°ë„ ì¡°ì •
            base_confidence = 60.0
            
            if self.market_condition:
                if self.market_condition.risk_level == "LOW":
                    base_confidence += 20
                elif self.market_condition.risk_level == "HIGH":
                    base_confidence -= 15
                elif self.market_condition.risk_level == "CRITICAL":
                    base_confidence -= 30
            
            # ê¸°ìˆ ì  ì§€í‘œ í™•ì‹ ë„
            rsi = features['rsi_14'].iloc[-1] if 'rsi_14' in features.columns else 50
            if 30 <= rsi <= 70:  # ì¤‘ê°„ ë²”ìœ„
                base_confidence += 10
            
            return max(20, min(95, base_confidence))
            
        except Exception:
            return 50.0
    
    def _calculate_risk_score(self, features: pd.DataFrame, predicted_return: float) -> float:
        """ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚° (0-100, ë†’ì„ìˆ˜ë¡ ìœ„í—˜)"""
        try:
            risk_score = 50.0  # ê¸°ë³¸ê°’
            
            # ë³€ë™ì„± ê¸°ë°˜ ë¦¬ìŠ¤í¬
            if 'volatility_20' in features.columns:
                volatility = features['volatility_20'].iloc[-1]
                risk_score += volatility * 1000  # ë³€ë™ì„±ì´ ë†’ìœ¼ë©´ ë¦¬ìŠ¤í¬ ì¦ê°€
            
            # ì˜ˆì¸¡ ìˆ˜ìµë¥  ê·¹ê°’ ì²´í¬
            if abs(predicted_return) > 10:  # 10% ì´ìƒì˜ ê·¹ë‹¨ì  ì˜ˆì¸¡
                risk_score += 20
            
            # ì‹œì¥ ì¡°ê±´ ë¦¬ìŠ¤í¬
            if self.market_condition:
                if self.market_condition.risk_level == "HIGH":
                    risk_score += 20
                elif self.market_condition.risk_level == "CRITICAL":
                    risk_score += 40
            
            return max(10, min(90, risk_score))
            
        except Exception:
            return 50.0
    
    def _determine_recommendation(self, predicted_return: float, confidence: float, risk_score: float) -> str:
        """ì¶”ì²œ ë“±ê¸‰ ê²°ì •"""
        
        # ê³ ìœ„í—˜ ìƒí™©ì—ì„œëŠ” ë³´ìˆ˜ì  ì ‘ê·¼
        if risk_score > 70:
            if predicted_return > 3 and confidence > 70:
                return "HOLD"
            else:
                return "SELL"
        
        # ì¼ë°˜ì ì¸ ì¶”ì²œ ë¡œì§
        if predicted_return > 5 and confidence > 70:
            return "STRONG_BUY"
        elif predicted_return > 2 and confidence > 60:
            return "BUY"
        elif predicted_return > -2 and predicted_return <= 2:
            return "HOLD"
        elif predicted_return > -5:
            return "SELL"
        else:
            return "STRONG_SELL"
    
    def _generate_reasoning(self, features: pd.DataFrame, predicted_return: float, stock: StockMaster) -> List[str]:
        """ì¶”ë¡  ì´ìœ  ìƒì„±"""
        reasoning = []
        
        try:
            # ê¸°ìˆ ì  ë¶„ì„ ì´ìœ 
            if 'rsi_14' in features.columns:
                rsi = features['rsi_14'].iloc[-1]
                if rsi < 30:
                    reasoning.append("RSI ê³¼ë§¤ë„ ì‹ í˜¸ (ìƒìŠ¹ ê°€ëŠ¥ì„±)")
                elif rsi > 70:
                    reasoning.append("RSI ê³¼ë§¤ìˆ˜ ì‹ í˜¸ (ì¡°ì • ê°€ëŠ¥ì„±)")
            
            # íŠ¸ë Œë“œ ë¶„ì„
            if 'sma_20' in features.columns and 'close' in features.columns:
                price = features['close'].iloc[-1]
                sma20 = features['sma_20'].iloc[-1]
                if price > sma20:
                    reasoning.append("20ì¼ ì´í‰ì„  ìƒíšŒ (ìƒìŠ¹ íŠ¸ë Œë“œ)")
                else:
                    reasoning.append("20ì¼ ì´í‰ì„  í•˜íšŒ (í•˜ë½ íŠ¸ë Œë“œ)")
            
            # ì‹œì¥ ì²´ì œ ì˜í–¥
            if self.market_condition:
                reasoning.append(f"ì‹œì¥ ì²´ì œ: {self.market_condition.regime.value}")
                reasoning.append(f"ë¦¬ìŠ¤í¬ ìˆ˜ì¤€: {self.market_condition.risk_level}")
            
            # ì˜ˆì¸¡ ê°•ë„
            if abs(predicted_return) > 5:
                reasoning.append("ê°•í•œ ê°€ê²© ëª¨ë©˜í…€ ì˜ˆìƒ")
            elif abs(predicted_return) < 1:
                reasoning.append("íš¡ë³´ íŒ¨í„´ ì˜ˆìƒ")
            
        except Exception:
            reasoning.append("ê¸°ë³¸ ê¸°ìˆ ì  ë¶„ì„ ê¸°ë°˜")
        
        return reasoning if reasoning else ["í¬ê´„ì  ì‹œì¥ ë¶„ì„ ê¸°ë°˜"]


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    engine = GlobalMLEngine()
    
    # 1. ëª¨ë¸ í•™ìŠµ
    print("ğŸ‹ï¸ ê¸€ë¡œë²Œ ML ëª¨ë¸ í•™ìŠµ...")
    if engine.train_global_models():
        print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    else:
        print("âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
        return False
    
    # 2. ì˜ˆì¸¡ ì‹¤í–‰
    print("\nğŸ¯ ê¸€ë¡œë²Œ ì˜ˆì¸¡ ì‹¤í–‰...")
    
    # í•œêµ­ ì˜ˆì¸¡
    kr_predictions = engine.predict_stocks(MarketRegion.KR, top_n=5)
    print(f"\nğŸ‡°ğŸ‡· í•œêµ­ ìƒìœ„ 5ê°œ ì¶”ì²œ:")
    for pred in kr_predictions:
        print(f"  {pred.stock_code}: {pred.predicted_return:.2f}% ({pred.recommendation})")
    
    # ë¯¸êµ­ ì˜ˆì¸¡
    us_predictions = engine.predict_stocks(MarketRegion.US, top_n=5)
    print(f"\nğŸ‡ºğŸ‡¸ ë¯¸êµ­ ìƒìœ„ 5ê°œ ì¶”ì²œ:")
    for pred in us_predictions:
        print(f"  {pred.stock_code}: {pred.predicted_return:.2f}% ({pred.recommendation})")
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
