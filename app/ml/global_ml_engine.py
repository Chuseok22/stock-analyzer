"""
ê¸€ë¡œë²Œ ML ì—”ì§„ - í•œêµ­/ë¯¸êµ­ ì£¼ì‹ ì‹œì¥ í†µí•© ë¶„ì„
Market Regime Detection, Cross-Market Correlation, Deep Feature Engineering
"""
import sys
from pathlib import Path
from datetime import datetime, date, timedelta
from typing import List, Dict, Any, Optional, Tuple
import numpy as np
import pandas as pd
from dataclasses import dataclass
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

# ML Libraries
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
from sklearn.linear_model import Ridge, ElasticNet
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib

# Add app directory to path
sys.path.append(str(Path(__file__).parent.parent.parent / "app"))

from app.database.connection import get_db_session
from app.models.entities import (
    StockMaster, StockDailyPrice, StockTechnicalIndicator, 
    StockFundamentalData, MarketRegion
)


class MarketRegime(Enum):
    """ì‹œì¥ ì²´ì œ ë¶„ë¥˜"""
    BULL_MARKET = "bull_market"        # ê°•ì„¸ì¥
    BEAR_MARKET = "bear_market"        # ì•½ì„¸ì¥  
    SIDEWAYS_MARKET = "sideways_market" # íš¡ë³´ì¥
    HIGH_VOLATILITY = "high_volatility" # ê³ ë³€ë™ì„±
    CRISIS_MODE = "crisis_mode"         # ìœ„ê¸° ìƒí™©


@dataclass
class MarketCondition:
    """ì‹œì¥ ìƒí™© ì •ë³´"""
    regime: MarketRegime
    volatility_level: float
    correlation_kr_us: float
    fear_greed_index: float
    trend_strength: float
    risk_level: str  # LOW, MEDIUM, HIGH, CRITICAL


@dataclass
class GlobalPrediction:
    """ê¸€ë¡œë²Œ ì˜ˆì¸¡ ê²°ê³¼"""
    stock_code: str
    market_region: str
    predicted_return: float
    confidence_score: float
    risk_score: float
    recommendation: str  # BUY, HOLD, SELL, STRONG_BUY, STRONG_SELL
    target_price: Optional[float]
    stop_loss: Optional[float]
    reasoning: List[str]


class GlobalMLEngine:
    """ê¸€ë¡œë²Œ ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§„"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.market_condition = None
        self.model_version = "v3.0_global"
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.model_dir = Path(__file__).parent.parent.parent / "storage" / "models" / "global"
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        print("ğŸŒ ê¸€ë¡œë²Œ ML ì—”ì§„ ì´ˆê¸°í™”")
    
    def detect_market_regime(self) -> Any:
        """ê¸€ë¡œë²Œ ì‹œì¥ ì²´ì œ ê°ì§€"""
        print("ğŸ” ê¸€ë¡œë²Œ ì‹œì¥ ì²´ì œ ë¶„ì„ ì¤‘...")
        
        try:
            # ì„ì‹œ MockMarketCondition í´ë˜ìŠ¤ ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
            class MockMarketCondition:
                def __init__(self):
                    # MarketRegime Enumê³¼ í˜¸í™˜ë˜ëŠ” ê°ì²´ ìƒì„±
                    class MockRegime:
                        def __init__(self, value):
                            self.value = value
                    
                    self.regime = MockRegime("BULL_MARKET")  # MarketRegime í˜¸í™˜
                    self.volatility_level = 0.15
                    self.risk_level = "MEDIUM"
                    self.trend_strength = 0.75
                    self.fear_greed_index = 65
            
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì—¬ê¸°ì„œ ì‹œì¥ ë°ì´í„°ë¥¼ ë¶„ì„
            # í˜„ì¬ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ mock ê°ì²´ ë°˜í™˜
            return MockMarketCondition()
            
        except Exception as e:
            print(f"âŒ ì‹œì¥ ì²´ì œ ê°ì§€ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ ê°ì²´ ë°˜í™˜
            class DefaultMarketCondition:
                def __init__(self):
                    class DefaultRegime:
                        def __init__(self, value):
                            self.value = value
                    
                    self.regime = DefaultRegime("UNKNOWN")
                    self.volatility_level = 0.0
                    self.risk_level = "UNKNOWN"
                    self.trend_strength = 0.5
                    self.fear_greed_index = 50
            
            return DefaultMarketCondition()
    
    def save_predictions_for_learning(self, predictions: List, target_date: date = None):
        """í•™ìŠµì„ ìœ„í•œ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥"""
        if target_date is None:
            target_date = date.today()
        
        try:
            # ì‹¤ì‹œê°„ í•™ìŠµ ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            from app.ml.realtime_learning_system import RealTimeLearningSystem
            
            learning_system = RealTimeLearningSystem()
            learning_system.save_daily_predictions(predictions, target_date)
            
        except Exception as e:
            print(f"âŒ í•™ìŠµìš© ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    def _get_market_index_data(self, db, region: MarketRegion, start_date: date, end_date: date) -> List[float]:
        """ì‹œì¥ ì§€ìˆ˜ ëŒ€í‘œ ë°ì´í„° ì¶”ì¶œ"""
        try:
            if region == MarketRegion.KR:
                # í•œêµ­: ì‚¼ì„±ì „ì + SKí•˜ì´ë‹‰ìŠ¤ + NAVER í‰ê·  (ì‹œì´ ìƒìœ„ ëŒ€í‘œ)
                symbols = ['005930', '000660', '035420']
            else:
                # ë¯¸êµ­: AAPL + MSFT + GOOGL í‰ê·  (ì‹œì´ ìƒìœ„ ëŒ€í‘œ)
                symbols = ['AAPL', 'MSFT', 'GOOGL']
            
            market_prices = []
            
            for symbol in symbols:
                stock = db.query(StockMaster).filter_by(
                    market_region=region.value,
                    stock_code=symbol
                ).first()
                
                if stock:
                    prices = db.query(StockDailyPrice).filter(
                        StockDailyPrice.stock_id == stock.stock_id,
                        StockDailyPrice.trade_date >= start_date,
                        StockDailyPrice.trade_date <= end_date
                    ).order_by(StockDailyPrice.trade_date).all()
                    
                    if prices:
                        symbol_prices = [float(p.close_price) for p in prices]
                        market_prices.append(symbol_prices)
            
            if market_prices:
                # í‰ê·  ê³„ì‚° (ê° ë‚ ì§œë³„ë¡œ)
                min_length = min(len(prices) for prices in market_prices)
                avg_prices = []
                
                for i in range(min_length):
                    day_avg = sum(prices[i] for prices in market_prices) / len(market_prices)
                    avg_prices.append(day_avg)
                
                return avg_prices
            
            return []
            
        except Exception as e:
            print(f"âŒ {region.value} ì‹œì¥ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    def _calculate_trend_strength(self, returns: pd.Series) -> float:
        """íŠ¸ë Œë“œ ê°•ë„ ê³„ì‚°"""
        if len(returns) < 5:
            return 0.0
        
        # ë‹¨ìˆœ íŠ¸ë Œë“œ ê°•ë„: ì—°ì† ìƒìŠ¹/í•˜ë½ ì¼ìˆ˜ì˜ ì ˆëŒ“ê°’
        cumulative_return = (1 + returns).cumprod()
        
        # ì„ í˜• íšŒê·€ë¥¼ í†µí•œ íŠ¸ë Œë“œ ê°•ë„
        x = np.arange(len(cumulative_return))
        z = np.polyfit(x, cumulative_return, 1)
        
        # ê¸°ìš¸ê¸°ì˜ ì ˆëŒ“ê°’ì„ íŠ¸ë Œë“œ ê°•ë„ë¡œ ì‚¬ìš©
        trend_strength = abs(z[0]) * 100
        
        return min(trend_strength, 10.0)  # ìµœëŒ€ 10ìœ¼ë¡œ ì œí•œ
    
    def _calculate_fear_greed_index(self, kr_returns: pd.Series, us_returns: pd.Series, volatility: float) -> float:
        """ê³µí¬/íƒìš• ì§€ìˆ˜ ê³„ì‚° (0: ê·¹ë„ì˜ ê³µí¬, 100: ê·¹ë„ì˜ íƒìš•)"""
        try:
            # ìµœê·¼ ìˆ˜ìµë¥  í‰ê· 
            recent_kr = kr_returns.tail(10).mean()
            recent_us = us_returns.tail(10).mean()
            avg_return = (recent_kr + recent_us) / 2
            
            # ë³€ë™ì„± ì •ê·œí™” (ë‚®ìœ¼ë©´ íƒìš•, ë†’ìœ¼ë©´ ê³µí¬)
            volatility_score = max(0, min(100, 100 - (volatility * 10)))
            
            # ìˆ˜ìµë¥  ì •ê·œí™”
            return_score = max(0, min(100, 50 + (avg_return * 1000)))
            
            # ê°€ì¤‘ í‰ê· 
            fear_greed = (volatility_score * 0.6) + (return_score * 0.4)
            
            return fear_greed
            
        except Exception:
            return 50.0  # ì¤‘ë¦½
    
    def _determine_market_regime(self, volatility: float, trend_strength: float, fear_greed: float) -> MarketRegime:
        """ì‹œì¥ ì²´ì œ ê²°ì •"""
        
        # ê·¹ë„ì˜ ë³€ë™ì„± ì²´í¬
        if volatility > 0.4:  # 40% ì´ìƒ
            return MarketRegime.HIGH_VOLATILITY
        
        # ìœ„ê¸° ìƒí™© ì²´í¬
        if fear_greed < 20 and volatility > 0.3:
            return MarketRegime.CRISIS_MODE
        
        # íŠ¸ë Œë“œ ê¸°ë°˜ ë¶„ë¥˜
        if trend_strength > 3.0:  # ê°•í•œ íŠ¸ë Œë“œ
            if fear_greed > 60:
                return MarketRegime.BULL_MARKET
            elif fear_greed < 40:
                return MarketRegime.BEAR_MARKET
        
        # ê¸°ë³¸ê°’: íš¡ë³´ì¥
        return MarketRegime.SIDEWAYS_MARKET
    
    def _determine_risk_level(self, volatility: float, correlation: float, fear_greed: float) -> str:
        """ë¦¬ìŠ¤í¬ ë ˆë²¨ ê²°ì •"""
        
        if volatility > 0.4 or fear_greed < 20:
            return "CRITICAL"
        elif volatility > 0.3 or fear_greed < 30:
            return "HIGH"
        elif volatility > 0.2 or abs(correlation) > 0.8:
            return "MEDIUM"
        else:
            return "LOW"
    
    def _get_default_market_condition(self) -> MarketCondition:
        """ê¸°ë³¸ ì‹œì¥ ìƒí™©"""
        return MarketCondition(
            regime=MarketRegime.SIDEWAYS_MARKET,
            volatility_level=0.2,
            correlation_kr_us=0.5,
            fear_greed_index=50.0,
            trend_strength=2.0,
            risk_level="MEDIUM"
        )
    
    def prepare_global_features(self, stock_id: int, target_date: date) -> Optional[pd.DataFrame]:
        """ê¸€ë¡œë²Œ í”¼ì²˜ ìƒì„± - ë”¥ëŸ¬ë‹ ìˆ˜ì¤€ì˜ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
        print(f"ğŸ”§ ê¸€ë¡œë²Œ í”¼ì²˜ ìƒì„±: stock_id={stock_id}, date={target_date}")
        
        try:
            with get_db_session() as db:
                # ê¸°ë³¸ ì •ë³´
                stock = db.query(StockMaster).filter_by(stock_id=stock_id).first()
                if not stock:
                    return None
                
                # 120ì¼ íˆìŠ¤í† ë¦¬ ë°ì´í„°
                end_date = target_date
                start_date = end_date - timedelta(days=120)
                
                # ê°€ê²© ë°ì´í„°
                price_data = db.query(StockDailyPrice).filter(
                    StockDailyPrice.stock_id == stock_id,
                    StockDailyPrice.trade_date >= start_date,
                    StockDailyPrice.trade_date <= end_date
                ).order_by(StockDailyPrice.trade_date).all()
                
                if len(price_data) < 30:
                    print(f"   âš ï¸ ê°€ê²© ë°ì´í„° ë¶€ì¡±: {len(price_data)}ì¼")
                    return None
                
                # ê¸°ìˆ ì  ì§€í‘œ ë°ì´í„°
                tech_data = db.query(StockTechnicalIndicator).filter(
                    StockTechnicalIndicator.stock_id == stock_id,
                    StockTechnicalIndicator.calculation_date >= start_date,
                    StockTechnicalIndicator.calculation_date <= end_date
                ).order_by(StockTechnicalIndicator.calculation_date).all()
                
                # DataFrame ìƒì„±
                df = self._build_feature_dataframe(price_data, tech_data, stock)
                
                # ê³ ê¸‰ í”¼ì²˜ ì¶”ê°€
                df = self._add_advanced_features(df, stock)
                
                # í¬ë¡œìŠ¤ ë§ˆì¼“ í”¼ì²˜ (ìƒê´€ê´€ê³„ ë“±)
                df = self._add_cross_market_features(df, stock, target_date)
                
                # ì‹œì¥ ì²´ì œ í”¼ì²˜
                if self.market_condition:
                    df = self._add_market_regime_features(df)
                
                print(f"   âœ… í”¼ì²˜ ìƒì„± ì™„ë£Œ: {len(df)} í–‰, {len(df.columns)} í”¼ì²˜")
                return df
                
        except Exception as e:
            print(f"   âŒ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _build_feature_dataframe(self, price_data: List, tech_data: List, stock: StockMaster) -> pd.DataFrame:
        """ê¸°ë³¸ í”¼ì²˜ DataFrame êµ¬ì„±"""
        
        # ê°€ê²© ë°ì´í„° ë³€í™˜
        price_df = pd.DataFrame([{
            'date': p.trade_date,
            'open': float(p.open_price),
            'high': float(p.high_price),
            'low': float(p.low_price),
            'close': float(p.close_price),
            'volume': p.volume,
            'adjusted_close': float(p.adjusted_close_price) if p.adjusted_close_price else float(p.close_price),
            'daily_return': p.daily_return_pct or 0.0,
            'vwap': float(p.vwap) if p.vwap else float(p.close_price)
        } for p in price_data])
        
        # ê¸°ìˆ ì  ì§€í‘œ ë°ì´í„° ë³€í™˜
        tech_df = pd.DataFrame([{
            'date': t.calculation_date,
            'rsi_14': t.rsi_14,
            'sma_5': t.sma_5,
            'sma_20': t.sma_20,
            'sma_50': t.sma_50,
            'ema_12': t.ema_12,
            'ema_26': t.ema_26,
            'bb_upper': t.bb_upper_20_2,
            'bb_lower': t.bb_lower_20_2,
            'bb_percent': t.bb_percent,
            'macd': t.macd_line,
            'macd_signal': t.macd_signal,
            'volume_ratio': t.volume_ratio
        } for t in tech_data])
        
        # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ê²°í•©
        df = pd.merge(price_df, tech_df, on='date', how='left')
        
        # ê¸°ë³¸ í”¼ì²˜ ì¶”ê°€
        df['price_range'] = (df['high'] - df['low']) / df['close']
        df['open_close_ratio'] = df['open'] / df['close']
        df['high_close_ratio'] = df['high'] / df['close']
        df['low_close_ratio'] = df['low'] / df['close']
        df['volume_price_trend'] = df['volume'] * df['daily_return']
        
        return df.fillna(method='ffill').fillna(0)
    
    def _add_advanced_features(self, df: pd.DataFrame, stock: StockMaster) -> pd.DataFrame:
        """ê³ ê¸‰ í”¼ì²˜ ì¶”ê°€ - ë”¥ëŸ¬ë‹ ìŠ¤íƒ€ì¼"""
        
        # 1. ì‹œê³„ì—´ ìœˆë„ìš° í”¼ì²˜ (3, 5, 10, 20ì¼)
        for window in [3, 5, 10, 20]:
            # ê°€ê²© ëª¨ë©˜í…€
            df[f'price_momentum_{window}'] = df['close'].pct_change(window)
            
            # ë³€ë™ì„±
            df[f'volatility_{window}'] = df['daily_return'].rolling(window).std()
            
            # ê±°ë˜ëŸ‰ í‰ê· 
            df[f'volume_ma_{window}'] = df['volume'].rolling(window).mean()
            
            # ìµœê³ ê°€/ìµœì €ê°€ ëŒ€ë¹„ í˜„ì¬ ìœ„ì¹˜
            df[f'high_position_{window}'] = (df['close'] - df['low'].rolling(window).min()) / (
                df['high'].rolling(window).max() - df['low'].rolling(window).min()
            )
        
        # 2. ê¸°ìˆ ì  ë¶„ì„ ê³ ê¸‰ í”¼ì²˜
        # RSI ê¸°ë°˜ í”¼ì²˜
        df['rsi_ma_5'] = df['rsi_14'].rolling(5).mean()
        df['rsi_divergence'] = df['rsi_14'] - df['rsi_ma_5']
        df['rsi_extreme'] = ((df['rsi_14'] > 70) | (df['rsi_14'] < 30)).astype(int)
        
        # ë³¼ë¦°ì € ë°´ë“œ ê¸°ë°˜ í”¼ì²˜
        df['bb_squeeze'] = (df['bb_upper'] - df['bb_lower']) / df['close']
        df['bb_position'] = df['bb_percent']
        df['bb_breakout'] = ((df['close'] > df['bb_upper']) | (df['close'] < df['bb_lower'])).astype(int)
        
        # 3. ê°€ê²© íŒ¨í„´ í”¼ì²˜
        # ê°­ ë¶„ì„
        df['gap_up'] = ((df['open'] > df['close'].shift(1)) & 
                       (df['open'] - df['close'].shift(1)) / df['close'].shift(1) > 0.02).astype(int)
        df['gap_down'] = ((df['open'] < df['close'].shift(1)) & 
                         (df['close'].shift(1) - df['open']) / df['close'].shift(1) > 0.02).astype(int)
        
        # ìº”ë“¤ìŠ¤í‹± íŒ¨í„´
        df['doji'] = (abs(df['open'] - df['close']) / (df['high'] - df['low']) < 0.1).astype(int)
        df['hammer'] = ((df['close'] > df['open']) & 
                       ((df['open'] - df['low']) > 2 * (df['close'] - df['open']))).astype(int)
        
        # 4. ë§ˆì¼“ ë§ˆì´í¬ë¡œìŠ¤íŠ¸ëŸ­ì²˜ í”¼ì²˜
        # ê±°ë˜ëŸ‰ í”„ë¡œíŒŒì¼
        df['volume_surge'] = (df['volume'] > df['volume'].rolling(20).mean() * 2).astype(int)
        df['volume_dry'] = (df['volume'] < df['volume'].rolling(20).mean() * 0.5).astype(int)
        
        # ê°€ê²©-ê±°ë˜ëŸ‰ ìƒê´€ê´€ê³„
        df['price_volume_corr'] = df['daily_return'].rolling(20).corr(df['volume'].pct_change())
        
        return df.fillna(0)
    
    def _add_cross_market_features(self, df: pd.DataFrame, stock: StockMaster, target_date: date) -> pd.DataFrame:
        """í¬ë¡œìŠ¤ ë§ˆì¼“ í”¼ì²˜ ì¶”ê°€"""
        
        try:
            # ìƒëŒ€ ì‹œì¥ ì •ë³´
            other_region = MarketRegion.US if stock.market_region == MarketRegion.KR.value else MarketRegion.KR
            
            with get_db_session() as db:
                # ë‹¤ë¥¸ ì‹œì¥ì˜ ëŒ€í‘œ ì§€ìˆ˜ ë°ì´í„°
                other_market_data = self._get_market_index_data(
                    db, other_region, 
                    target_date - timedelta(days=60), 
                    target_date
                )
                
                if other_market_data:
                    # ë‹¤ë¥¸ ì‹œì¥ ìˆ˜ìµë¥  ê³„ì‚°
                    other_returns = pd.Series(other_market_data).pct_change().fillna(0)
                    
                    # ìµœê·¼ ìƒê´€ê´€ê³„
                    if len(other_returns) >= len(df['daily_return']):
                        recent_other = other_returns.tail(len(df))
                        df['cross_market_corr'] = df['daily_return'].rolling(20).corr(recent_other)
                    
                    # ë‹¤ë¥¸ ì‹œì¥ íŠ¸ë Œë“œ ì˜í–¥
                    if len(other_returns) > 0:
                        other_trend = other_returns.tail(5).mean()
                        df['other_market_trend'] = other_trend
                        df['cross_market_momentum'] = df['daily_return'] * other_trend
                
        except Exception as e:
            print(f"   âš ï¸ í¬ë¡œìŠ¤ ë§ˆì¼“ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return df.fillna(0)
    
    def _add_market_regime_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì‹œì¥ ì²´ì œ í”¼ì²˜ ì¶”ê°€"""
        
        if not self.market_condition:
            return df
        
        # ì‹œì¥ ì²´ì œ ë”ë¯¸ ë³€ìˆ˜
        for regime in MarketRegime:
            df[f'regime_{regime.value}'] = (self.market_condition.regime == regime).astype(int)
        
        # ì‹œì¥ ì¡°ê±´ í”¼ì²˜
        df['market_volatility'] = self.market_condition.volatility_level
        df['market_correlation'] = self.market_condition.correlation_kr_us
        df['market_fear_greed'] = self.market_condition.fear_greed_index
        df['market_trend_strength'] = self.market_condition.trend_strength
        
        # ë¦¬ìŠ¤í¬ ë ˆë²¨ ë”ë¯¸ ë³€ìˆ˜
        for risk in ['LOW', 'MEDIUM', 'HIGH', 'CRITICAL']:
            df[f'risk_{risk.lower()}'] = (self.market_condition.risk_level == risk).astype(int)
        
        return df
    
    def train_global_models(self, use_intensive_config: bool = False) -> bool:
        """ê¸€ë¡œë²Œ ML ëª¨ë¸ í•™ìŠµ - ë°°í¬ í™˜ê²½ ìµœì í™”"""
        print("ğŸ‹ï¸ ê¸€ë¡œë²Œ ML ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        try:
            # ë°°í¬ í™˜ê²½ ê°ì§€
            is_production = Path("/volume1/project/stock-analyzer").exists()
            
            if is_production:
                print("ğŸš€ ë°°í¬ í™˜ê²½ ê°ì§€ - ê³ ì„±ëŠ¥ í•™ìŠµ ëª¨ë“œ")
                # ë°°í¬ í™˜ê²½ì—ì„œëŠ” ìµœëŒ€ ì„±ëŠ¥ìœ¼ë¡œ í•™ìŠµ
                model_config = {
                    'n_estimators': 300,        # íŠ¸ë¦¬ ê°œìˆ˜ ì¦ê°€
                    'max_depth': 12,            # ê¹Šì´ ì¦ê°€
                    'min_samples_split': 5,     # ë” ì„¸ë°€í•œ ë¶„í• 
                    'min_samples_leaf': 2,      # ë¦¬í”„ ë…¸ë“œ ìµœì†Œê°’
                    'max_features': 'sqrt',     # ëª¨ë“  í”¼ì²˜ ì‚¬ìš©
                    'random_state': 42,
                    'n_jobs': -1,              # ëª¨ë“  CPU ì½”ì–´ í™œìš©
                    'verbose': 1               # ì§„í–‰ìƒí™© í‘œì‹œ
                }
                
                if use_intensive_config or hasattr(self, 'model_config'):
                    # ì§‘ì¤‘ í•™ìŠµ ëª¨ë“œ
                    intensive_config = getattr(self, 'model_config', {})
                    if intensive_config:
                        model_config.update(intensive_config)
                        print(f"ğŸ”¥ ì§‘ì¤‘ í•™ìŠµ ì„¤ì • ì ìš©: {intensive_config}")
            else:
                print("ğŸ› ï¸ ê°œë°œ í™˜ê²½ - ë¹ ë¥¸ í•™ìŠµ ëª¨ë“œ")
                # ê°œë°œ í™˜ê²½ì—ì„œëŠ” ë¹ ë¥¸ í•™ìŠµ
                model_config = {
                    'n_estimators': 50,
                    'max_depth': 8,
                    'min_samples_split': 10,
                    'random_state': 42,
                    'n_jobs': 2
                }
            
            print(f"âš™ï¸ ëª¨ë¸ ì„¤ì •: {model_config}")
            
            # 1. ë°ì´í„° ì¤€ë¹„
            print("ğŸ“Š í•™ìŠµ ë°ì´í„° ì¤€ë¹„...")
            training_success = self._prepare_training_data()
            
            if not training_success:
                print("âŒ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨")
                return False
            
            # 2. í•œêµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ
            print("ğŸ‡°ğŸ‡· í•œêµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
            kr_success = self._train_market_model(MarketRegion.KR, model_config)
            
            # 3. ë¯¸êµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ
            print("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
            us_success = self._train_market_model(MarketRegion.US, model_config)
            
            # 4. ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
            print("ğŸŒ ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ...")
            ensemble_success = self._train_ensemble_model(model_config)
            
            success = kr_success and us_success and ensemble_success
            
            if success:
                if is_production:
                    print("ğŸ‰ ë°°í¬ í™˜ê²½ ê³ ì„±ëŠ¥ í•™ìŠµ ì™„ë£Œ!")
                else:
                    print("âœ… ê°œë°œ í™˜ê²½ í•™ìŠµ ì™„ë£Œ")
                
                # ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦
                self._validate_trained_models()
            else:
                print("âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
            
            return success
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def _prepare_training_data(self) -> bool:
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ë° ê²€ì¦"""
        print("ğŸ” í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        try:
            with get_db_session() as db:
                # í•œêµ­ ì‹œì¥ ë°ì´í„° í™•ì¸
                kr_stocks = db.query(StockMaster).filter_by(
                    market_region=MarketRegion.KR.value,
                    is_active=True
                ).count()
                
                # ë¯¸êµ­ ì‹œì¥ ë°ì´í„° í™•ì¸
                us_stocks = db.query(StockMaster).filter_by(
                    market_region=MarketRegion.US.value,
                    is_active=True
                ).count()
                
                # ìµœê·¼ ë°ì´í„° í™•ì¸
                recent_date = datetime.now().date() - timedelta(days=7)
                
                kr_recent_data = db.query(StockDailyPrice).join(StockMaster).filter(
                    StockMaster.market_region == MarketRegion.KR.value,
                    StockDailyPrice.date >= recent_date
                ).count()
                
                us_recent_data = db.query(StockDailyPrice).join(StockMaster).filter(
                    StockMaster.market_region == MarketRegion.US.value,
                    StockDailyPrice.date >= recent_date
                ).count()
                
                print(f"   ğŸ‡°ğŸ‡· í•œêµ­ ì¢…ëª©: {kr_stocks}ê°œ, ìµœê·¼ ë°ì´í„°: {kr_recent_data}ê°œ")
                print(f"   ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì¢…ëª©: {us_stocks}ê°œ, ìµœê·¼ ë°ì´í„°: {us_recent_data}ê°œ")
                
                # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ê²€ì¦
                if kr_stocks < 10 or us_stocks < 10:
                    print("   âŒ ì¢…ëª© ë°ì´í„° ë¶€ì¡±")
                    return False
                
                if kr_recent_data < 50 or us_recent_data < 50:
                    print("   âŒ ìµœê·¼ ê°€ê²© ë°ì´í„° ë¶€ì¡±")
                    return False
                
                print("   âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
                return True
                
        except Exception as e:
            print(f"   âŒ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return False
            
            if not training_success:
                print("âŒ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨")
                return False
    
    def _prepare_training_data(self) -> bool:
        """í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ë° ê²€ì¦"""
        print("ğŸ” í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        try:
            with get_db_session() as db:
                # í•œêµ­ ì‹œì¥ ë°ì´í„° í™•ì¸
                kr_stocks = db.query(StockMaster).filter_by(
                    market_region=MarketRegion.KR.value,
                    is_active=True
                ).count()
                
                # ë¯¸êµ­ ì‹œì¥ ë°ì´í„° í™•ì¸
                us_stocks = db.query(StockMaster).filter_by(
                    market_region=MarketRegion.US.value,
                    is_active=True
                ).count()
                
                # ìµœê·¼ ë°ì´í„° í™•ì¸
                recent_date = datetime.now().date() - timedelta(days=7)
                
                kr_recent_data = db.query(StockDailyPrice).join(StockMaster).filter(
                    StockMaster.market_region == MarketRegion.KR.value,
                    StockDailyPrice.date >= recent_date
                ).count()
                
                us_recent_data = db.query(StockDailyPrice).join(StockMaster).filter(
                    StockMaster.market_region == MarketRegion.US.value,
                    StockDailyPrice.date >= recent_date
                ).count()
                
                print(f"   ğŸ‡°ğŸ‡· í•œêµ­ ì¢…ëª©: {kr_stocks}ê°œ, ìµœê·¼ ë°ì´í„°: {kr_recent_data}ê°œ")
                print(f"   ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì¢…ëª©: {us_stocks}ê°œ, ìµœê·¼ ë°ì´í„°: {us_recent_data}ê°œ")
                
                # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­ ê²€ì¦
                if kr_stocks < 10 or us_stocks < 10:
                    print("   âŒ ì¢…ëª© ë°ì´í„° ë¶€ì¡±")
                    return False
                
                if kr_recent_data < 50 or us_recent_data < 50:
                    print("   âŒ ìµœê·¼ ê°€ê²© ë°ì´í„° ë¶€ì¡±")
                    return False
                
                print("   âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ")
                return True
                
        except Exception as e:
            print(f"   âŒ ë°ì´í„° ì¤€ë¹„ ì‹¤íŒ¨: {e}")
            return False
            
            # 2. í•œêµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ
            print("ğŸ‡°ğŸ‡· í•œêµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
            kr_success = self._train_market_model(MarketRegion.KR, model_config)
            
            # 3. ë¯¸êµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ
            print("ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
            us_success = self._train_market_model(MarketRegion.US, model_config)
            
            # 4. ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ
            print("ğŸŒ ê¸€ë¡œë²Œ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ...")
            ensemble_success = self._train_ensemble_model(model_config)
            
            success = kr_success and us_success and ensemble_success
            
            if success:
                if is_production:
                    print("ğŸ‰ ë°°í¬ í™˜ê²½ ê³ ì„±ëŠ¥ í•™ìŠµ ì™„ë£Œ!")
                else:
                    print("âœ… ê°œë°œ í™˜ê²½ í•™ìŠµ ì™„ë£Œ")
                
                # ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦
                self._validate_trained_models()
            else:
                print("âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
            
            return success
            
        except Exception as e:
            print(f"âŒ ê¸€ë¡œë²Œ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return False
    
    def _validate_trained_models(self):
        """í•™ìŠµëœ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦"""
        try:
            print("ğŸ” í•™ìŠµëœ ëª¨ë¸ ì„±ëŠ¥ ê²€ì¦...")
            
            # ëª¨ë¸ íŒŒì¼ ì¡´ì¬ í™•ì¸
            model_dir = Path("storage/models/global")
            required_models = [
                "global_kr_model.joblib",
                "global_us_model.joblib", 
                "global_ensemble_model.joblib"
            ]
            
            model_status = {}
            for model_name in required_models:
                model_path = model_dir / model_name
                if model_path.exists():
                    model_status[model_name] = "âœ… ì¡´ì¬"
                    # íŒŒì¼ í¬ê¸° í™•ì¸
                    size_mb = model_path.stat().st_size / (1024 * 1024)
                    model_status[model_name] += f" ({size_mb:.1f}MB)"
                else:
                    model_status[model_name] = "âŒ ì—†ìŒ"
            
            print("ğŸ“‹ ëª¨ë¸ íŒŒì¼ ìƒíƒœ:")
            for model, status in model_status.items():
                print(f"   â€¢ {model}: {status}")
            
            # ëª¨ë“  ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            all_exist = all("âœ…" in status for status in model_status.values())
            if all_exist:
                print("âœ… ëª¨ë“  ëª¨ë¸ íŒŒì¼ ê²€ì¦ ì™„ë£Œ")
            else:
                print("âš ï¸ ì¼ë¶€ ëª¨ë¸ íŒŒì¼ ëˆ„ë½")
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
    
    def _train_market_model(self, region: MarketRegion, model_config: dict = None) -> bool:
        """ì‹œì¥ë³„ ëª¨ë¸ í•™ìŠµ"""
        print(f"ğŸ¯ {region.value} ì‹œì¥ ëª¨ë¸ í•™ìŠµ...")
        
        if model_config is None:
            model_config = {
                'n_estimators': 100,
                'max_depth': 10,
                'random_state': 42,
                'n_jobs': -1
            }
        
        try:
            with get_db_session() as db:
                # í•´ë‹¹ ì‹œì¥ ì¢…ëª© ëª©ë¡
                stocks = db.query(StockMaster).filter_by(
                    market_region=region.value,
                    is_active=True
                ).all()
                
                all_features = []
                all_targets = []
                sample_weights = []  # ê°€ì¤‘ì¹˜ ì¶”ê°€
                
                for stock in stocks[:20]:  # ìƒìœ„ 20ê°œ ì¢…ëª©ìœ¼ë¡œ ì œí•œ
                    print(f"   ğŸ“Š {stock.stock_code} ë°ì´í„° ìˆ˜ì§‘...")
                    
                    # ìµœê·¼ 180ì¼ ë°ì´í„°
                    end_date = datetime.now().date()
                    
                    for days_back in range(30, 150):  # ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
                        current_date = end_date - timedelta(days=days_back)
                        
                        # í”¼ì²˜ ìƒì„±
                        features = self.prepare_global_features(stock.stock_id, current_date)
                        
                        if features is None or len(features) < 30:
                            continue
                        
                        # íƒ€ê²Ÿ ìƒì„± (5ì¼ í›„ ìˆ˜ìµë¥ )
                        future_date = current_date + timedelta(days=5)
                        target = self._get_future_return(db, stock.stock_id, current_date, future_date)
                        
                        if target is None:
                            continue
                        
                        # ìµœì‹  ë°ì´í„° ì‚¬ìš©
                        latest_features = features.iloc[-1].fillna(0)
                        
                        # ê°€ì¤‘ì¹˜ ê³„ì‚° (ìµœì‹  ë°ì´í„°ì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜)
                        time_weight = 1.0 / (days_back / 30.0 + 1.0)  # ì‹œê°„ ê°€ì¤‘ì¹˜
                        
                        # ë³€ë™ì„± ê°€ì¤‘ì¹˜ (ë†’ì€ ë³€ë™ì„±ì€ ë‚®ì€ ê°€ì¤‘ì¹˜)
                        volatility = features['volatility_20d'].iloc[-1] if 'volatility_20d' in features.columns else 0.02
                        volatility_weight = 1.0 / (volatility * 50 + 1.0)
                        
                        # ê±°ë˜ëŸ‰ ê°€ì¤‘ì¹˜ (ë†’ì€ ê±°ë˜ëŸ‰ì€ ë†’ì€ ê°€ì¤‘ì¹˜)
                        volume_ratio = features.get('volume_ratio', pd.Series([1.0])).iloc[-1]
                        volume_weight = min(volume_ratio / 2.0 + 0.5, 2.0)
                        
                        # ìµœì¢… ê°€ì¤‘ì¹˜
                        final_weight = time_weight * volatility_weight * volume_weight
                        
                        all_features.append(latest_features)
                        all_targets.append(target)
                        sample_weights.append(final_weight)
                
                if len(all_features) < 50:
                    print(f"   âš ï¸ {region.value}: í•™ìŠµ ë°ì´í„° ë¶€ì¡± ({len(all_features)}ê°œ)")
                    return False
                
                # DataFrame ë³€í™˜
                X = pd.DataFrame(all_features)
                y = np.array(all_targets)
                weights = np.array(sample_weights)
                
                print(f"   ğŸ“ˆ í•™ìŠµ ë°ì´í„°: {len(X)}ê°œ ìƒ˜í”Œ, {len(X.columns)}ê°œ í”¼ì²˜")
                print(f"   âš–ï¸ ê°€ì¤‘ì¹˜ ë²”ìœ„: {weights.min():.3f} - {weights.max():.3f}")
                
                # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
                scaler = RobustScaler()  # ì•„ì›ƒë¼ì´ì–´ì— ê°•ê±´í•œ ìŠ¤ì¼€ì¼ëŸ¬
                X_scaled = scaler.fit_transform(X)
                
                # ì•™ìƒë¸” ëª¨ë¸ ìƒì„± (ê°€ì¤‘ì¹˜ ì ìš©)
                rf_model = RandomForestRegressor(**model_config)
                gb_model = GradientBoostingRegressor(
                    n_estimators=model_config.get('n_estimators', 100),
                    max_depth=model_config.get('max_depth', 10),
                    random_state=model_config.get('random_state', 42)
                )
                
                ensemble_model = VotingRegressor([
                    ('rf', rf_model),
                    ('gb', gb_model)
                ])
                
                # ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ëª¨ë¸ í•™ìŠµ
                print(f"   ğŸ‹ï¸ ê°€ì¤‘ì¹˜ ì ìš© ëª¨ë¸ í•™ìŠµ ì¤‘...")
                ensemble_model.fit(X_scaled, y, sample_weight=weights)
                
                # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
                y_pred = ensemble_model.predict(X_scaled)
                mse = mean_squared_error(y, y_pred, sample_weight=weights)
                r2 = r2_score(y, y_pred, sample_weight=weights)
                
                print(f"   ğŸ“Š ì„±ëŠ¥ ì§€í‘œ - MSE: {mse:.4f}, RÂ²: {r2:.4f}")
                
                # í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„
                if hasattr(ensemble_model.estimators_[0], 'feature_importances_'):
                    feature_importance = ensemble_model.estimators_[0].feature_importances_
                    top_features = pd.Series(feature_importance, index=X.columns).nlargest(10)
                    print(f"   ğŸ¯ ì£¼ìš” í”¼ì²˜:")
                    for feature, importance in top_features.items():
                        print(f"      {feature}: {importance:.3f}")
                
                # ëª¨ë¸ ì €ì¥
                self.models[region.value] = ensemble_model
                self.scalers[region.value] = scaler
                
                model_path = self.model_dir / f"{region.value}_ensemble_model.pkl"
                scaler_path = self.model_dir / f"{region.value}_scaler.pkl"
                
                joblib.dump(ensemble_model, model_path)
                joblib.dump(scaler, scaler_path)
                
                print(f"   âœ… {region.value} ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
                return True
                
                print(f"   ğŸ“ˆ í•™ìŠµ ë°ì´í„°: {len(X)}ê°œ ìƒ˜í”Œ, {len(X.columns)}ê°œ í”¼ì²˜")
                
                # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
                scaler = RobustScaler()
                X_scaled = scaler.fit_transform(X)
                
                # ëª¨ë¸ ì •ì˜ (ì•™ìƒë¸”)
                models = {
                    'rf': RandomForestRegressor(
                        n_estimators=200,
                        max_depth=15,
                        min_samples_split=10,
                        min_samples_leaf=5,
                        random_state=42,
                        n_jobs=-1
                    ),
                    'gbm': GradientBoostingRegressor(
                        n_estimators=150,
                        max_depth=8,
                        learning_rate=0.1,
                        subsample=0.8,
                        random_state=42
                    ),
                    'ridge': Ridge(alpha=1.0, random_state=42)
                }
                
                # ê°œë³„ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
                model_scores = {}
                trained_models = {}
                
                tscv = TimeSeriesSplit(n_splits=5)
                
                for name, model in models.items():
                    print(f"   ğŸ”§ {name} ëª¨ë¸ í•™ìŠµ...")
                    
                    # êµì°¨ ê²€ì¦
                    cv_scores = cross_val_score(model, X_scaled, y, cv=tscv, scoring='neg_mean_squared_error')
                    mse_score = -cv_scores.mean()
                    
                    # ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ
                    model.fit(X_scaled, y)
                    
                    model_scores[name] = mse_score
                    trained_models[name] = model
                    
                    print(f"      MSE: {mse_score:.6f}")
                
                # ì•™ìƒë¸” ëª¨ë¸ ìƒì„±
                best_models = sorted(model_scores.items(), key=lambda x: x[1])[:2]  # ìƒìœ„ 2ê°œ
                ensemble_models = [(name, trained_models[name]) for name, _ in best_models]
                
                ensemble = VotingRegressor(estimators=ensemble_models)
                ensemble.fit(X_scaled, y)
                
                # ìµœì¢… í‰ê°€
                ensemble_score = -cross_val_score(ensemble, X_scaled, y, cv=tscv, scoring='neg_mean_squared_error').mean()
                print(f"   ğŸ¯ ì•™ìƒë¸” MSE: {ensemble_score:.6f}")
                
                # ëª¨ë¸ ì €ì¥
                model_path = self.model_dir / f"{region.value}_model_{self.model_version}.joblib"
                scaler_path = self.model_dir / f"{region.value}_scaler_{self.model_version}.joblib"
                
                joblib.dump(ensemble, model_path)
                joblib.dump(scaler, scaler_path)
                
                # ë©”ëª¨ë¦¬ì— ì €ì¥
                self.models[region.value] = ensemble
                self.scalers[region.value] = scaler
                
                print(f"   âœ… {region.value} ëª¨ë¸ ì €ì¥: {model_path}")
                return True
                
        except Exception as e:
            print(f"   âŒ {region.value} ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return False
    
    def _get_future_return(self, db, stock_id: int, current_date: date, future_date: date) -> Optional[float]:
        """ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°"""
        try:
            current_price = db.query(StockDailyPrice).filter(
                StockDailyPrice.stock_id == stock_id,
                StockDailyPrice.trade_date == current_date
            ).first()
            
            future_price = db.query(StockDailyPrice).filter(
                StockDailyPrice.stock_id == stock_id,
                StockDailyPrice.trade_date >= future_date,
                StockDailyPrice.trade_date <= future_date + timedelta(days=7)
            ).first()
            
            if current_price and future_price:
                return_pct = (float(future_price.close_price) - float(current_price.close_price)) / float(current_price.close_price) * 100
                return return_pct
            
            return None
            
        except Exception:
            return None
    
    def predict_stocks(self, region: MarketRegion, top_n: int = 5) -> List[GlobalPrediction]:
        """ì£¼ì‹ ì˜ˆì¸¡ ì‹¤í–‰"""
        print(f"ğŸ¯ {region.value} ì£¼ì‹ ì˜ˆì¸¡ ì¤‘... (ìƒìœ„ {top_n}ê°œ)")
        
        predictions = []
        
        try:
            # ëª¨ë¸ ë¡œë“œ
            if region.value not in self.models:
                self._load_model(region)
            
            if region.value not in self.models:
                print(f"   âŒ {region.value} ëª¨ë¸ ì—†ìŒ")
                return []
            
            model = self.models[region.value]
            scaler = self.scalers[region.value]
            
            with get_db_session() as db:
                # ì¢…ëª© ëª©ë¡
                stocks = db.query(StockMaster).filter_by(
                    market_region=region.value,
                    is_active=True
                ).all()
                
                target_date = datetime.now().date()
                
                for stock in stocks:
                    try:
                        # í”¼ì²˜ ìƒì„±
                        features = self.prepare_global_features(stock.stock_id, target_date)
                        
                        if features is None or len(features) == 0:
                            continue
                        
                        # ì˜ˆì¸¡ ì‹¤í–‰
                        latest_features = features.iloc[-1].fillna(0)
                        X_scaled = scaler.transform([latest_features])
                        
                        predicted_return = model.predict(X_scaled)[0]
                        
                        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (ê°„ì†Œí™”)
                        confidence = self._calculate_confidence(features, predicted_return)
                        
                        # ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚°
                        risk_score = self._calculate_risk_score(features, predicted_return)
                        
                        # ì¶”ì²œ ë“±ê¸‰ ê²°ì •
                        recommendation = self._determine_recommendation(predicted_return, confidence, risk_score)
                        
                        # ëª©í‘œê°€/ì†ì ˆê°€ ê³„ì‚°
                        current_price = float(features['close'].iloc[-1])
                        target_price = current_price * (1 + predicted_return / 100)
                        stop_loss = current_price * 0.95  # 5% ì†ì ˆ
                        
                        # ì¶”ë¡  ì´ìœ 
                        reasoning = self._generate_reasoning(features, predicted_return, stock)
                        
                        prediction = GlobalPrediction(
                            stock_code=stock.stock_code,
                            market_region=region.value,
                            predicted_return=predicted_return,
                            confidence_score=confidence,
                            risk_score=risk_score,
                            recommendation=recommendation,
                            target_price=target_price,
                            stop_loss=stop_loss,
                            reasoning=reasoning
                        )
                        
                        predictions.append(prediction)
                        
                    except Exception as e:
                        print(f"   âš ï¸ {stock.stock_code}: {e}")
                        continue
                
            # ìˆ˜ìµë¥  ê¸°ì¤€ ì •ë ¬
            predictions.sort(key=lambda x: x.predicted_return, reverse=True)
            
            print(f"   âœ… {len(predictions)}ê°œ ì¢…ëª© ì˜ˆì¸¡ ì™„ë£Œ")
            return predictions[:top_n]
            
        except Exception as e:
            print(f"   âŒ {region.value} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return []
    
    def _load_model(self, region: MarketRegion):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            model_path = self.model_dir / f"{region.value}_model_{self.model_version}.joblib"
            scaler_path = self.model_dir / f"{region.value}_scaler_{self.model_version}.joblib"
            
            if model_path.exists() and scaler_path.exists():
                self.models[region.value] = joblib.load(model_path)
                self.scalers[region.value] = joblib.load(scaler_path)
                print(f"   âœ… {region.value} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"   âš ï¸ {region.value} ëª¨ë¸ íŒŒì¼ ì—†ìŒ")
                
        except Exception as e:
            print(f"   âŒ {region.value} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _calculate_confidence(self, features: pd.DataFrame, predicted_return: float) -> float:
        """ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚°"""
        try:
            # ì‹œì¥ ì¡°ê±´ì— ë”°ë¥¸ ì‹ ë¢°ë„ ì¡°ì •
            base_confidence = 60.0
            
            if self.market_condition:
                if self.market_condition.risk_level == "LOW":
                    base_confidence += 20
                elif self.market_condition.risk_level == "HIGH":
                    base_confidence -= 15
                elif self.market_condition.risk_level == "CRITICAL":
                    base_confidence -= 30
            
            # ê¸°ìˆ ì  ì§€í‘œ í™•ì‹ ë„
            rsi = features['rsi_14'].iloc[-1] if 'rsi_14' in features.columns else 50
            if 30 <= rsi <= 70:  # ì¤‘ê°„ ë²”ìœ„
                base_confidence += 10
            
            return max(20, min(95, base_confidence))
            
        except Exception:
            return 50.0
    
    def _calculate_risk_score(self, features: pd.DataFrame, predicted_return: float) -> float:
        """ë¦¬ìŠ¤í¬ ì ìˆ˜ ê³„ì‚° (0-100, ë†’ì„ìˆ˜ë¡ ìœ„í—˜)"""
        try:
            risk_score = 50.0  # ê¸°ë³¸ê°’
            
            # ë³€ë™ì„± ê¸°ë°˜ ë¦¬ìŠ¤í¬
            if 'volatility_20' in features.columns:
                volatility = features['volatility_20'].iloc[-1]
                risk_score += volatility * 1000  # ë³€ë™ì„±ì´ ë†’ìœ¼ë©´ ë¦¬ìŠ¤í¬ ì¦ê°€
            
            # ì˜ˆì¸¡ ìˆ˜ìµë¥  ê·¹ê°’ ì²´í¬
            if abs(predicted_return) > 10:  # 10% ì´ìƒì˜ ê·¹ë‹¨ì  ì˜ˆì¸¡
                risk_score += 20
            
            # ì‹œì¥ ì¡°ê±´ ë¦¬ìŠ¤í¬
            if self.market_condition:
                if self.market_condition.risk_level == "HIGH":
                    risk_score += 20
                elif self.market_condition.risk_level == "CRITICAL":
                    risk_score += 40
            
            return max(10, min(90, risk_score))
            
        except Exception:
            return 50.0
    
    def _determine_recommendation(self, predicted_return: float, confidence: float, risk_score: float) -> str:
        """ì¶”ì²œ ë“±ê¸‰ ê²°ì •"""
        
        # ê³ ìœ„í—˜ ìƒí™©ì—ì„œëŠ” ë³´ìˆ˜ì  ì ‘ê·¼
        if risk_score > 70:
            if predicted_return > 3 and confidence > 70:
                return "HOLD"
            else:
                return "SELL"
        
        # ì¼ë°˜ì ì¸ ì¶”ì²œ ë¡œì§
        if predicted_return > 5 and confidence > 70:
            return "STRONG_BUY"
        elif predicted_return > 2 and confidence > 60:
            return "BUY"
        elif predicted_return > -2 and predicted_return <= 2:
            return "HOLD"
        elif predicted_return > -5:
            return "SELL"
        else:
            return "STRONG_SELL"
    
    def _generate_reasoning(self, features: pd.DataFrame, predicted_return: float, stock: StockMaster) -> List[str]:
        """ì¶”ë¡  ì´ìœ  ìƒì„±"""
        reasoning = []
        
        try:
            # ê¸°ìˆ ì  ë¶„ì„ ì´ìœ 
            if 'rsi_14' in features.columns:
                rsi = features['rsi_14'].iloc[-1]
                if rsi < 30:
                    reasoning.append("RSI ê³¼ë§¤ë„ ì‹ í˜¸ (ìƒìŠ¹ ê°€ëŠ¥ì„±)")
                elif rsi > 70:
                    reasoning.append("RSI ê³¼ë§¤ìˆ˜ ì‹ í˜¸ (ì¡°ì • ê°€ëŠ¥ì„±)")
            
            # íŠ¸ë Œë“œ ë¶„ì„
            if 'sma_20' in features.columns and 'close' in features.columns:
                price = features['close'].iloc[-1]
                sma20 = features['sma_20'].iloc[-1]
                if price > sma20:
                    reasoning.append("20ì¼ ì´í‰ì„  ìƒíšŒ (ìƒìŠ¹ íŠ¸ë Œë“œ)")
                else:
                    reasoning.append("20ì¼ ì´í‰ì„  í•˜íšŒ (í•˜ë½ íŠ¸ë Œë“œ)")
            
            # ì‹œì¥ ì²´ì œ ì˜í–¥
            if self.market_condition:
                reasoning.append(f"ì‹œì¥ ì²´ì œ: {self.market_condition.regime.value}")
                reasoning.append(f"ë¦¬ìŠ¤í¬ ìˆ˜ì¤€: {self.market_condition.risk_level}")
            
            # ì˜ˆì¸¡ ê°•ë„
            if abs(predicted_return) > 5:
                reasoning.append("ê°•í•œ ê°€ê²© ëª¨ë©˜í…€ ì˜ˆìƒ")
            elif abs(predicted_return) < 1:
                reasoning.append("íš¡ë³´ íŒ¨í„´ ì˜ˆìƒ")
            
        except Exception:
            reasoning.append("ê¸°ë³¸ ê¸°ìˆ ì  ë¶„ì„ ê¸°ë°˜")
        
        return reasoning if reasoning else ["í¬ê´„ì  ì‹œì¥ ë¶„ì„ ê¸°ë°˜"]


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    engine = GlobalMLEngine()
    
    # 1. ëª¨ë¸ í•™ìŠµ
    print("ğŸ‹ï¸ ê¸€ë¡œë²Œ ML ëª¨ë¸ í•™ìŠµ...")
    if engine.train_global_models():
        print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    else:
        print("âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
        return False
    
    # 2. ì˜ˆì¸¡ ì‹¤í–‰
    print("\nğŸ¯ ê¸€ë¡œë²Œ ì˜ˆì¸¡ ì‹¤í–‰...")
    
    # í•œêµ­ ì˜ˆì¸¡
    kr_predictions = engine.predict_stocks(MarketRegion.KR, top_n=5)
    print(f"\nğŸ‡°ğŸ‡· í•œêµ­ ìƒìœ„ 5ê°œ ì¶”ì²œ:")
    for pred in kr_predictions:
        print(f"  {pred.stock_code}: {pred.predicted_return:.2f}% ({pred.recommendation})")
    
    # ë¯¸êµ­ ì˜ˆì¸¡
    us_predictions = engine.predict_stocks(MarketRegion.US, top_n=5)
    print(f"\nğŸ‡ºğŸ‡¸ ë¯¸êµ­ ìƒìœ„ 5ê°œ ì¶”ì²œ:")
    for pred in us_predictions:
        print(f"  {pred.stock_code}: {pred.predicted_return:.2f}% ({pred.recommendation})")
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
