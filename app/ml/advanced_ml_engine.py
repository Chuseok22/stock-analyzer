#!/usr/bin/env python3
"""
ê³ ë„í™”ëœ ML ì—”ì§„ - ë”¥ëŸ¬ë‹, ê³ ê¸‰ ì•™ìƒë¸”, ì‹œê³„ì—´ íŠ¹í™”
- LSTM/GRU ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡
- Transformer ì•„í‚¤í…ì²˜ ì ìš©
- ê³ ê¸‰ ì•™ìƒë¸” (Stacking, Blending)
- ë² ì´ì§€ì•ˆ ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- ë©€í‹° íƒœìŠ¤í¬ í•™ìŠµ
"""
import sys
from pathlib import Path
from datetime import datetime, date, timedelta
from typing import List, Dict, Any, Optional, Tuple, Union
import numpy as np
import pandas as pd
from dataclasses import dataclass
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

# ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import Dataset, DataLoader
    from sklearn.preprocessing import MinMaxScaler
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    # PyTorch ë¯¸ì„¤ì¹˜ì‹œ ë”ë¯¸ í´ë˜ìŠ¤ ì •ì˜
    class Dataset:
        pass
    class nn:
        class Module:
            pass
        class LSTM:
            pass
        class MultiheadAttention:
            pass
        class Linear:
            pass
        class ReLU:
            pass
        class Dropout:
            pass
        class BatchNorm1d:
            pass
        class Sequential:
            pass
        class TransformerEncoderLayer:
            pass
        class TransformerEncoder:
            pass
    class torch:
        class FloatTensor:
            pass
        @staticmethod
        def zeros(*args, **kwargs):
            return None
        @staticmethod
        def arange(*args, **kwargs):
            return None
        @staticmethod
        def exp(*args, **kwargs):
            return None
        @staticmethod
        def sin(*args, **kwargs):
            return None
        @staticmethod
        def cos(*args, **kwargs):
            return None
        @staticmethod
        def device(*args, **kwargs):
            return "cpu"
        @staticmethod
        def save(*args, **kwargs):
            pass
    class optim:
        class AdamW:
            pass
        class lr_scheduler:
            class ReduceLROnPlateau:
                pass
    print("âš ï¸ PyTorch ë¯¸ì„¤ì¹˜ - ê¸°ë³¸ ëª¨ë¸ë¡œ ëŒ€ì²´")

# ML ë¼ì´ë¸ŒëŸ¬ë¦¬
from sklearn.ensemble import (
    RandomForestRegressor, GradientBoostingRegressor, 
    VotingRegressor, StackingRegressor
)
from sklearn.linear_model import Ridge, ElasticNet, BayesianRidge
from sklearn.svm import SVR
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV

# ë² ì´ì§€ì•ˆ ìµœì í™” (ì„ íƒì )
try:
    from skopt import BayesSearchCV
    from skopt.space import Real, Integer
    BAYESIAN_OPTIMIZATION_AVAILABLE = True
except ImportError:
    BAYESIAN_OPTIMIZATION_AVAILABLE = False

import joblib
import json

# Add app directory to path
sys.path.append(str(Path(__file__).parent.parent.parent / "app"))

from app.database.connection import get_db_session
from app.models.entities import StockMaster, StockDailyPrice, MarketRegion
from app.services.dynamic_universe_manager import DynamicUniverseManager


class ModelType(Enum):
    """ëª¨ë¸ ìœ í˜•"""
    LSTM = "lstm"
    GRU = "gru"
    TRANSFORMER = "transformer"
    STACKING_ENSEMBLE = "stacking_ensemble"
    VOTING_ENSEMBLE = "voting_ensemble"
    BAYESIAN_RIDGE = "bayesian_ridge"
    HYBRID_DEEP_ML = "hybrid_deep_ml"


@dataclass
class ModelPerformance:
    """ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ"""
    model_type: str
    mse: float
    mae: float
    r2_score: float
    directional_accuracy: float
    sharpe_ratio: float
    max_drawdown: float
    training_time: float
    prediction_time: float


class StockSequenceDataset(Dataset):
    """ì£¼ì‹ ì‹œê³„ì—´ ë°ì´í„°ì…‹ (PyTorch)"""
    
    def __init__(self, sequences: np.ndarray, targets: np.ndarray):
        self.sequences = torch.FloatTensor(sequences)
        self.targets = torch.FloatTensor(targets)
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        return self.sequences[idx], self.targets[idx]


class LSTMPredictor(nn.Module):
    """LSTM ê¸°ë°˜ ì£¼ì‹ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 3, 
                 dropout: float = 0.2, output_size: int = 1):
        super(LSTMPredictor, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTM ë ˆì´ì–´
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout,
            batch_first=True,
            bidirectional=True
        )
        
        # ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_size * 2,  # bidirectional
            num_heads=8,
            dropout=dropout,
            batch_first=True
        )
        
        # ì™„ì „ ì—°ê²° ë ˆì´ì–´
        self.fc_layers = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, output_size)
        )
        
        # ë°°ì¹˜ ì •ê·œí™”
        self.batch_norm = nn.BatchNorm1d(hidden_size * 2)
        
    def forward(self, x):
        # LSTM ì²˜ë¦¬
        lstm_out, _ = self.lstm(x)
        
        # ì–´í…ì…˜ ì ìš©
        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)
        
        # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ì„ íƒ
        last_output = attn_out[:, -1, :]
        
        # ë°°ì¹˜ ì •ê·œí™”
        normalized = self.batch_norm(last_output)
        
        # ì™„ì „ ì—°ê²° ë ˆì´ì–´
        output = self.fc_layers(normalized)
        
        return output


class TransformerPredictor(nn.Module):
    """Transformer ê¸°ë°˜ ì£¼ì‹ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, input_size: int, d_model: int = 256, nhead: int = 8, 
                 num_layers: int = 6, dropout: float = 0.1):
        super(TransformerPredictor, self).__init__()
        
        self.d_model = d_model
        self.input_projection = nn.Linear(input_size, d_model)
        
        # í¬ì§€ì…”ë„ ì¸ì½”ë”©
        self.positional_encoding = self._create_positional_encoding(1000, d_model)
        
        # Transformer ì¸ì½”ë”
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # ì¶œë ¥ ë ˆì´ì–´
        self.output_layer = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, 1)
        )
        
    def _create_positional_encoding(self, max_len: int, d_model: int):
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1).float()
        
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           -(np.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        return pe.unsqueeze(0)
    
    def forward(self, x):
        batch_size, seq_len, _ = x.shape
        
        # ì…ë ¥ íˆ¬ì˜
        x = self.input_projection(x)
        
        # í¬ì§€ì…”ë„ ì¸ì½”ë”© ì¶”ê°€
        x += self.positional_encoding[:, :seq_len, :].to(x.device)
        
        # Transformer ì²˜ë¦¬
        transformer_out = self.transformer(x)
        
        # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ì˜ ì¶œë ¥ ì‚¬ìš©
        last_output = transformer_out[:, -1, :]
        
        # ìµœì¢… ì˜ˆì¸¡
        output = self.output_layer(last_output)
        
        return output


class AdvancedMLEngine:
    """ê³ ë„í™”ëœ ML ì—”ì§„"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.performance_history = {}
        self.model_version = "v4.0_advanced"
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.model_dir = Path(__file__).parent.parent.parent / "storage" / "models" / "advanced"
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # ë™ì  ìœ ë‹ˆë²„ìŠ¤ ê´€ë¦¬ì
        self.universe_manager = DynamicUniverseManager()
        
        # ì‹œí€€ìŠ¤ ê¸¸ì´ (ì‹œê³„ì—´ ì…ë ¥)
        self.sequence_length = 60  # 60ì¼ ì‹œê³„ì—´
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ì‚¬ìš© ê°€ëŠ¥ì‹œ)
        if TORCH_AVAILABLE:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            print(f"ğŸ”§ PyTorch ë””ë°”ì´ìŠ¤: {self.device}")
        
        print("ğŸ§  ê³ ë„í™”ëœ ML ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def prepare_sequence_features(self, stock_id: int, target_date: date, 
                                sequence_length: int = None) -> Optional[np.ndarray]:
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„±"""
        if sequence_length is None:
            sequence_length = self.sequence_length
            
        print(f"ğŸ“Š ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„±: stock_id={stock_id}, length={sequence_length}")
        
        try:
            with get_db_session() as db:
                # ì¶©ë¶„í•œ ê¸°ê°„ì˜ ë°ì´í„° ì¡°íšŒ
                end_date = target_date
                start_date = end_date - timedelta(days=sequence_length * 2)  # ì—¬ìœ ë¶„
                
                prices = db.query(StockDailyPrice).filter(
                    StockDailyPrice.stock_id == stock_id,
                    StockDailyPrice.trade_date >= start_date,
                    StockDailyPrice.trade_date <= end_date
                ).order_by(StockDailyPrice.trade_date).all()
                
                if len(prices) < sequence_length + 10:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ëŸ‰
                    return None
                
                # ê¸°ë³¸ OHLCV ë°ì´í„°
                data = []
                for price in prices:
                    row = [
                        float(price.open_price),
                        float(price.high_price),
                        float(price.low_price),
                        float(price.close_price),
                        float(price.volume) if price.volume else 0,
                        float(price.daily_return_pct) if price.daily_return_pct else 0
                    ]
                    data.append(row)
                
                df = pd.DataFrame(data, columns=['open', 'high', 'low', 'close', 'volume', 'return'])
                
                # ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€
                df = self._add_advanced_technical_indicators(df)
                
                # ì‹œì¥ ë¯¸ì‹œêµ¬ì¡° í”¼ì²˜ ì¶”ê°€
                df = self._add_microstructure_features(df)
                
                # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
                if len(df) < sequence_length:
                    return None
                
                # ë§ˆì§€ë§‰ sequence_length ë§Œí¼ ì‚¬ìš©
                sequence_data = df.iloc[-sequence_length:].values
                
                # NaN ì²˜ë¦¬
                sequence_data = np.nan_to_num(sequence_data, nan=0.0, posinf=1.0, neginf=-1.0)
                
                return sequence_data.astype(np.float32)
                
        except Exception as e:
            print(f"âŒ ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def _add_advanced_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ì¶”ê°€"""
        try:
            # ì´ë™í‰ê· ë“¤
            for window in [5, 10, 20, 50]:
                df[f'sma_{window}'] = df['close'].rolling(window, min_periods=1).mean()
                df[f'ema_{window}'] = df['close'].ewm(span=window).mean()
            
            # RSI
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
            rs = gain / loss.replace(0, 1e-8)
            df['rsi'] = 100 - (100 / (1 + rs))
            
            # MACD
            ema_12 = df['close'].ewm(span=12).mean()
            ema_26 = df['close'].ewm(span=26).mean()
            df['macd'] = ema_12 - ema_26
            df['macd_signal'] = df['macd'].ewm(span=9).mean()
            df['macd_histogram'] = df['macd'] - df['macd_signal']
            
            # ë³¼ë¦°ì € ë°´ë“œ
            sma_20 = df['close'].rolling(20, min_periods=1).mean()
            std_20 = df['close'].rolling(20, min_periods=1).std()
            df['bb_upper'] = sma_20 + (std_20 * 2)
            df['bb_lower'] = sma_20 - (std_20 * 2)
            df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower']).replace(0, 1e-8)
            
            # ìŠ¤í† ìºìŠ¤í‹±
            low_14 = df['low'].rolling(14, min_periods=1).min()
            high_14 = df['high'].rolling(14, min_periods=1).max()
            df['stoch_k'] = 100 * (df['close'] - low_14) / (high_14 - low_14).replace(0, 1e-8)
            df['stoch_d'] = df['stoch_k'].rolling(3, min_periods=1).mean()
            
            # ë³€ë™ì„± ì§€í‘œ
            df['volatility_10'] = df['return'].rolling(10, min_periods=1).std()
            df['volatility_30'] = df['return'].rolling(30, min_periods=1).std()
            
            # ê±°ë˜ëŸ‰ ì§€í‘œ
            df['volume_sma_20'] = df['volume'].rolling(20, min_periods=1).mean()
            df['volume_ratio'] = df['volume'] / df['volume_sma_20'].replace(0, 1)
            
            # ê°€ê²© ë ˆì¸ì§€
            df['true_range'] = np.maximum(
                df['high'] - df['low'],
                np.maximum(
                    abs(df['high'] - df['close'].shift(1)),
                    abs(df['low'] - df['close'].shift(1))
                )
            )
            df['atr'] = df['true_range'].rolling(14, min_periods=1).mean()
            
            return df.fillna(method='ffill').fillna(0)
            
        except Exception as e:
            print(f"âš ï¸ ê³ ê¸‰ ê¸°ìˆ ì  ì§€í‘œ ìƒì„± ì‹¤íŒ¨: {e}")
            return df
    
    def _add_microstructure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ì‹œì¥ ë¯¸ì‹œêµ¬ì¡° í”¼ì²˜ ì¶”ê°€"""
        try:
            # ê°€ê²© ê°­
            df['gap'] = (df['open'] - df['close'].shift(1)) / df['close'].shift(1)
            
            # ì¼ì¤‘ ìˆ˜ìµë¥ 
            df['intraday_return'] = (df['close'] - df['open']) / df['open']
            
            # ìƒí•˜ ê·¸ë¦¼ì
            df['upper_shadow'] = (df['high'] - np.maximum(df['open'], df['close'])) / df['close']
            df['lower_shadow'] = (np.minimum(df['open'], df['close']) - df['low']) / df['close']
            
            # ëª¸í†µ í¬ê¸°
            df['body_size'] = abs(df['close'] - df['open']) / df['close']
            
            # ê°€ê²© ìœ„ì¹˜ (ì¼ì¤‘)
            df['price_position'] = (df['close'] - df['low']) / (df['high'] - df['low']).replace(0, 1e-8)
            
            # ê±°ë˜ëŸ‰ ê°€ì¤‘ í‰ê·  ê°€ê²© (VWAP ê·¼ì‚¬)
            df['vwap_approx'] = (df['high'] + df['low'] + df['close']) / 3
            
            # ëª¨ë©˜í…€ ì§€í‘œ
            for period in [5, 10, 20]:
                df[f'momentum_{period}'] = df['close'].pct_change(period)
                df[f'roc_{period}'] = (df['close'] - df['close'].shift(period)) / df['close'].shift(period)
            
            # ìƒëŒ€ ê°•ë„
            df['relative_volume'] = df['volume'] / df['volume'].rolling(20, min_periods=1).mean()
            
            return df.fillna(0)
            
        except Exception as e:
            print(f"âš ï¸ ë¯¸ì‹œêµ¬ì¡° í”¼ì²˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return df
    
    def create_sequences_and_targets(self, stock_ids: List[int], region: MarketRegion, 
                                   lookback_days: int = 180) -> Tuple[np.ndarray, np.ndarray]:
        """ì‹œê³„ì—´ ì‹œí€€ìŠ¤ì™€ íƒ€ê²Ÿ ìƒì„±"""
        print(f"ğŸ”„ {region.value} ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± ì¤‘...")
        
        try:
            all_sequences = []
            all_targets = []
            
            end_date = datetime.now().date()
            
            for stock_id in stock_ids[:50]:  # ì„±ëŠ¥ì„ ìœ„í•´ 50ê°œë¡œ ì œí•œ
                try:
                    # ë‚ ì§œë³„ ì‹œí€€ìŠ¤ ìƒì„±
                    for days_back in range(self.sequence_length + 5, lookback_days, 5):  # 5ì¼ ê°„ê²©
                        current_date = end_date - timedelta(days=days_back)
                        
                        # ì‹œí€€ìŠ¤ í”¼ì²˜ ìƒì„±
                        sequence = self.prepare_sequence_features(stock_id, current_date)
                        if sequence is None:
                            continue
                        
                        # íƒ€ê²Ÿ ìƒì„± (5ì¼ í›„ ìˆ˜ìµë¥ )
                        future_date = current_date + timedelta(days=5)
                        target = self._get_future_return(stock_id, current_date, future_date)
                        if target is None:
                            continue
                        
                        all_sequences.append(sequence)
                        all_targets.append(target)
                        
                except Exception as e:
                    print(f"âš ï¸ ì¢…ëª© {stock_id} ì‹œí€€ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
                    continue
            
            if not all_sequences:
                print(f"âŒ {region.value} ì‹œí€€ìŠ¤ ë°ì´í„° ì—†ìŒ")
                return None, None
            
            sequences = np.array(all_sequences)
            targets = np.array(all_targets)
            
            print(f"âœ… {region.value} ì‹œí€€ìŠ¤ ìƒì„± ì™„ë£Œ: {sequences.shape}")
            return sequences, targets
            
        except Exception as e:
            print(f"âŒ {region.value} ì‹œí€€ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}")
            return None, None
    
    def _get_future_return(self, stock_id: int, current_date: date, future_date: date) -> Optional[float]:
        """ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°"""
        try:
            with get_db_session() as db:
                current_price = db.query(StockDailyPrice).filter(
                    StockDailyPrice.stock_id == stock_id,
                    StockDailyPrice.trade_date == current_date
                ).first()
                
                future_price = db.query(StockDailyPrice).filter(
                    StockDailyPrice.stock_id == stock_id,
                    StockDailyPrice.trade_date >= future_date,
                    StockDailyPrice.trade_date <= future_date + timedelta(days=7)
                ).order_by(StockDailyPrice.trade_date.asc()).first()
                
                if current_price and future_price:
                    return_pct = (float(future_price.close_price) - float(current_price.close_price)) / float(current_price.close_price) * 100
                    return return_pct
                
                return None
                
        except Exception:
            return None
    
    def train_lstm_model(self, sequences: np.ndarray, targets: np.ndarray, 
                        region: MarketRegion) -> bool:
        """LSTM ëª¨ë¸ í•™ìŠµ"""
        if not TORCH_AVAILABLE:
            print("âš ï¸ PyTorch ë¯¸ì„¤ì¹˜ - LSTM í•™ìŠµ ê±´ë„ˆëœ€")
            return False
            
        print(f"ğŸ§  {region.value} LSTM ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        try:
            # ë°ì´í„° ì „ì²˜ë¦¬
            scaler = MinMaxScaler()
            sequences_scaled = scaler.fit_transform(
                sequences.reshape(-1, sequences.shape[-1])
            ).reshape(sequences.shape)
            
            # íƒ€ê²Ÿ ì •ê·œí™”
            target_scaler = MinMaxScaler()
            targets_scaled = target_scaler.fit_transform(targets.reshape(-1, 1)).flatten()
            
            # ë°ì´í„°ì…‹ ë¶„í• 
            split_idx = int(len(sequences_scaled) * 0.8)
            X_train, X_test = sequences_scaled[:split_idx], sequences_scaled[split_idx:]
            y_train, y_test = targets_scaled[:split_idx], targets_scaled[split_idx:]
            
            # ë°ì´í„°ì…‹ ìƒì„±
            train_dataset = StockSequenceDataset(X_train, y_train)
            test_dataset = StockSequenceDataset(X_test, y_test)
            
            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
            
            # ëª¨ë¸ ìƒì„±
            input_size = sequences.shape[-1]
            model = LSTMPredictor(input_size=input_size).to(self.device)
            
            # ì˜µí‹°ë§ˆì´ì € ë° ì†ì‹¤í•¨ìˆ˜
            optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)
            criterion = nn.MSELoss()
            
            # í•™ìŠµ
            model.train()
            best_loss = float('inf')
            patience_counter = 0
            
            for epoch in range(100):  # ìµœëŒ€ 100 ì—í¬í¬
                train_loss = 0.0
                for batch_X, batch_y in train_loader:
                    batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
                    
                    optimizer.zero_grad()
                    outputs = model(batch_X).squeeze()
                    loss = criterion(outputs, batch_y)
                    loss.backward()
                    
                    # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    
                    optimizer.step()
                    train_loss += loss.item()
                
                # ê²€ì¦
                model.eval()
                val_loss = 0.0
                with torch.no_grad():
                    for batch_X, batch_y in test_loader:
                        batch_X, batch_y = batch_X.to(self.device), batch_y.to(self.device)
                        outputs = model(batch_X).squeeze()
                        val_loss += criterion(outputs, batch_y).item()
                
                val_loss /= len(test_loader)
                scheduler.step(val_loss)
                
                if val_loss < best_loss:
                    best_loss = val_loss
                    patience_counter = 0
                    # ìµœê³  ëª¨ë¸ ì €ì¥
                    torch.save({
                        'model_state_dict': model.state_dict(),
                        'scaler': scaler,
                        'target_scaler': target_scaler,
                        'input_size': input_size
                    }, self.model_dir / f"{region.value}_lstm_{self.model_version}.pth")
                else:
                    patience_counter += 1
                
                if patience_counter >= 20:  # ì¡°ê¸° ì¢…ë£Œ
                    break
                
                if (epoch + 1) % 10 == 0:
                    print(f"   ì—í¬í¬ {epoch+1}: í•™ìŠµ ì†ì‹¤={train_loss/len(train_loader):.6f}, ê²€ì¦ ì†ì‹¤={val_loss:.6f}")
                
                model.train()
            
            # ëª¨ë¸ ì €ì¥
            self.models[f"{region.value}_lstm"] = model
            self.scalers[f"{region.value}_lstm"] = (scaler, target_scaler)
            
            print(f"âœ… {region.value} LSTM ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ {region.value} LSTM í•™ìŠµ ì‹¤íŒ¨: {e}")
            return False
    
    def train_advanced_ensemble(self, X: np.ndarray, y: np.ndarray, 
                              region: MarketRegion) -> bool:
        """ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ"""
        print(f"ğŸ¯ {region.value} ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        try:
            # ë² ì´ìŠ¤ ëª¨ë¸ë“¤ ì •ì˜
            base_models = [
                ('rf', RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)),
                ('gb', GradientBoostingRegressor(n_estimators=200, max_depth=8, random_state=42)),
                ('svr', SVR(kernel='rbf', gamma='scale')),
                ('ridge', Ridge(alpha=1.0)),
                ('elastic', ElasticNet(alpha=0.1, l1_ratio=0.5)),
                ('bayesian', BayesianRidge())
            ]
            
            # ìŠ¤íƒœí‚¹ ë©”íƒ€ ëª¨ë¸
            meta_model = Ridge(alpha=0.1)
            
            # ìŠ¤íƒœí‚¹ ì•™ìƒë¸” ìƒì„±
            stacking_model = StackingRegressor(
                estimators=base_models,
                final_estimator=meta_model,
                cv=5,
                n_jobs=-1
            )
            
            # ë°ì´í„° ì „ì²˜ë¦¬
            scaler = RobustScaler()
            X_scaled = scaler.fit_transform(X)
            
            # ë² ì´ì§€ì•ˆ ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (ê°€ëŠ¥í•œ ê²½ìš°)
            if BAYESIAN_OPTIMIZATION_AVAILABLE:
                print("   ğŸ” ë² ì´ì§€ì•ˆ ìµœì í™” í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹...")
                
                search_spaces = {
                    'rf__n_estimators': Integer(100, 300),
                    'rf__max_depth': Integer(10, 20),
                    'gb__n_estimators': Integer(100, 300),
                    'gb__learning_rate': Real(0.01, 0.2),
                    'final_estimator__alpha': Real(0.01, 10.0)
                }
                
                bayes_search = BayesSearchCV(
                    stacking_model,
                    search_spaces,
                    n_iter=20,
                    cv=3,
                    scoring='neg_mean_squared_error',
                    n_jobs=-1,
                    random_state=42
                )
                
                bayes_search.fit(X_scaled, y)
                best_model = bayes_search.best_estimator_
                
                print(f"   âœ… ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°: {bayes_search.best_params_}")
                
            else:
                # ê¸°ë³¸ ê·¸ë¦¬ë“œ ì„œì¹˜
                print("   ğŸ” ê·¸ë¦¬ë“œ ì„œì¹˜ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹...")
                
                param_grid = {
                    'rf__n_estimators': [150, 200],
                    'gb__n_estimators': [150, 200],
                    'final_estimator__alpha': [0.1, 1.0]
                }
                
                grid_search = GridSearchCV(
                    stacking_model,
                    param_grid,
                    cv=3,
                    scoring='neg_mean_squared_error',
                    n_jobs=-1
                )
                
                grid_search.fit(X_scaled, y)
                best_model = grid_search.best_estimator_
            
            # ìµœì¢… ëª¨ë¸ í•™ìŠµ
            best_model.fit(X_scaled, y)
            
            # ì„±ëŠ¥ í‰ê°€
            from sklearn.model_selection import cross_val_score
            cv_scores = cross_val_score(best_model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')
            
            print(f"   ğŸ“Š êµì°¨ê²€ì¦ MSE: {-cv_scores.mean():.6f} (Â±{cv_scores.std():.6f})")
            
            # ëª¨ë¸ ì €ì¥
            self.models[f"{region.value}_advanced_ensemble"] = best_model
            self.scalers[f"{region.value}_advanced_ensemble"] = scaler
            
            model_path = self.model_dir / f"{region.value}_advanced_ensemble_{self.model_version}.joblib"
            scaler_path = self.model_dir / f"{region.value}_advanced_ensemble_scaler_{self.model_version}.joblib"
            
            joblib.dump(best_model, model_path)
            joblib.dump(scaler, scaler_path)
            
            print(f"âœ… {region.value} ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ {region.value} ê³ ê¸‰ ì•™ìƒë¸” í•™ìŠµ ì‹¤íŒ¨: {e}")
            return False
    
    async def train_advanced_models(self, region: MarketRegion) -> bool:
        """ê³ ë„í™”ëœ ëª¨ë¸ë“¤ í•™ìŠµ"""
        print(f"ğŸš€ {region.value} ê³ ë„í™”ëœ ML ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        try:
            # 1. ë™ì  ìœ ë‹ˆë²„ìŠ¤ì—ì„œ ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            stock_codes = await self.universe_manager.get_current_universe(region)
            
            with get_db_session() as db:
                # ì¢…ëª© ID ì¡°íšŒ
                stocks = db.query(StockMaster).filter(
                    StockMaster.market_region == region.value,
                    StockMaster.is_active == True,
                    StockMaster.stock_code.in_(stock_codes)
                ).all()
                
                stock_ids = [stock.stock_id for stock in stocks]
            
            if not stock_ids:
                print(f"âŒ {region.value} í™œì„± ì¢…ëª© ì—†ìŒ")
                return False
            
            # 2. ì‹œê³„ì—´ ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
            sequences, targets = self.create_sequences_and_targets(stock_ids, region)
            
            if sequences is None or len(sequences) < 100:
                print(f"âŒ {region.value} í•™ìŠµ ë°ì´í„° ë¶€ì¡±")
                return False
            
            # 3. LSTM ëª¨ë¸ í•™ìŠµ
            lstm_success = self.train_lstm_model(sequences, targets, region)
            
            # 4. ê³ ê¸‰ ì•™ìƒë¸” ëª¨ë¸ í•™ìŠµ (í‰íƒ„í™”ëœ í”¼ì²˜ ì‚¬ìš©)
            X_flat = sequences.reshape(len(sequences), -1)  # ì‹œí€€ìŠ¤ë¥¼ í‰íƒ„í™”
            ensemble_success = self.train_advanced_ensemble(X_flat, targets, region)
            
            success = lstm_success or ensemble_success
            
            if success:
                print(f"ğŸ‰ {region.value} ê³ ë„í™”ëœ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
            else:
                print(f"âŒ {region.value} ëª¨ë“  ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨")
            
            return success
            
        except Exception as e:
            print(f"âŒ {region.value} ê³ ë„í™”ëœ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            return False
    
    async def predict_with_advanced_models(self, region: MarketRegion, 
                                         top_n: int = 10) -> List[Dict]:
        """ê³ ë„í™”ëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡"""
        print(f"ğŸ¯ {region.value} ê³ ë„í™”ëœ ì˜ˆì¸¡ ì‹¤í–‰...")
        
        try:
            # ë™ì  ìœ ë‹ˆë²„ìŠ¤ ì¢…ëª© ì¡°íšŒ
            stock_codes = await self.universe_manager.get_current_universe(region)
            
            predictions = []
            
            with get_db_session() as db:
                stocks = db.query(StockMaster).filter(
                    StockMaster.market_region == region.value,
                    StockMaster.is_active == True,
                    StockMaster.stock_code.in_(stock_codes)
                ).all()
                
                for stock in stocks[:50]:  # ì„±ëŠ¥ì„ ìœ„í•´ 50ê°œë¡œ ì œí•œ
                    try:
                        # í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ í”¼ì²˜ ìƒì„±
                        current_date = datetime.now().date()
                        sequence = self.prepare_sequence_features(stock.stock_id, current_date)
                        
                        if sequence is None:
                            continue
                        
                        # ì•™ìƒë¸” ì˜ˆì¸¡
                        ensemble_pred = self._predict_with_ensemble(sequence, region)
                        
                        # LSTM ì˜ˆì¸¡ (ê°€ëŠ¥í•œ ê²½ìš°)
                        lstm_pred = self._predict_with_lstm(sequence, region)
                        
                        # ì˜ˆì¸¡ ê²°í•© (ì•™ìƒë¸” 70%, LSTM 30%)
                        if ensemble_pred is not None and lstm_pred is not None:
                            final_pred = ensemble_pred * 0.7 + lstm_pred * 0.3
                        elif ensemble_pred is not None:
                            final_pred = ensemble_pred
                        elif lstm_pred is not None:
                            final_pred = lstm_pred
                        else:
                            continue
                        
                        # ì‹ ë¢°ë„ ê³„ì‚°
                        confidence = self._calculate_prediction_confidence(sequence, final_pred)
                        
                        predictions.append({
                            'stock_code': stock.stock_code,
                            'stock_name': stock.stock_name,
                            'predicted_return': final_pred,
                            'confidence': confidence,
                            'model_type': 'advanced_ensemble_lstm'
                        })
                        
                    except Exception as e:
                        print(f"âš ï¸ {stock.stock_code} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                        continue
            
            # ì˜ˆì¸¡ ìˆ˜ìµë¥  ê¸°ì¤€ ì •ë ¬
            predictions.sort(key=lambda x: x['predicted_return'], reverse=True)
            
            print(f"âœ… {region.value} ê³ ë„í™”ëœ ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ")
            return predictions[:top_n]
            
        except Exception as e:
            print(f"âŒ {region.value} ê³ ë„í™”ëœ ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            return []
    
    def _predict_with_ensemble(self, sequence: np.ndarray, region: MarketRegion) -> Optional[float]:
        """ì•™ìƒë¸” ëª¨ë¸ë¡œ ì˜ˆì¸¡"""
        try:
            model_key = f"{region.value}_advanced_ensemble"
            
            if model_key not in self.models:
                return None
            
            model = self.models[model_key]
            scaler = self.scalers[model_key]
            
            # ì‹œí€€ìŠ¤ë¥¼ í‰íƒ„í™”
            X_flat = sequence.reshape(1, -1)
            X_scaled = scaler.transform(X_flat)
            
            prediction = model.predict(X_scaled)[0]
            return float(prediction)
            
        except Exception:
            return None
    
    def _predict_with_lstm(self, sequence: np.ndarray, region: MarketRegion) -> Optional[float]:
        """LSTM ëª¨ë¸ë¡œ ì˜ˆì¸¡"""
        if not TORCH_AVAILABLE:
            return None
            
        try:
            model_key = f"{region.value}_lstm"
            
            if model_key not in self.models:
                return None
            
            model = self.models[model_key]
            scaler, target_scaler = self.scalers[model_key]
            
            # ì‹œí€€ìŠ¤ ì „ì²˜ë¦¬
            sequence_scaled = scaler.transform(sequence)
            sequence_tensor = torch.FloatTensor(sequence_scaled).unsqueeze(0).to(self.device)
            
            # ì˜ˆì¸¡
            model.eval()
            with torch.no_grad():
                prediction_scaled = model(sequence_tensor).cpu().numpy()[0]
                prediction = target_scaler.inverse_transform([[prediction_scaled]])[0][0]
            
            return float(prediction)
            
        except Exception:
            return None
    
    def _calculate_prediction_confidence(self, sequence: np.ndarray, prediction: float) -> float:
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        try:
            # ì‹œí€€ìŠ¤ ë°ì´í„°ì˜ ë³€ë™ì„± ê¸°ë°˜ ì‹ ë¢°ë„
            if len(sequence) < 10:
                return 0.5
            
            # ìµœê·¼ ë³€ë™ì„±
            recent_returns = sequence[-20:, 5] if sequence.shape[1] > 5 else sequence[-20:, -1]  # return ì»¬ëŸ¼
            volatility = np.std(recent_returns) if len(recent_returns) > 1 else 0.1
            
            # ì˜ˆì¸¡ ê°•ë„
            prediction_strength = min(abs(prediction) / 5.0, 1.0)  # 5% ê¸°ì¤€ ì •ê·œí™”
            
            # ë³€ë™ì„±ì´ ë‚®ê³  ì˜ˆì¸¡ì´ ê°•í• ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
            volatility_score = max(0.1, 1.0 - volatility * 10)  # ë³€ë™ì„± ì—­ìˆ˜
            strength_score = prediction_strength
            
            confidence = (volatility_score * 0.6 + strength_score * 0.4)
            return max(0.1, min(0.95, confidence))
            
        except Exception:
            return 0.5


# ì‚¬ìš© ì˜ˆì‹œ
async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§  ê³ ë„í™”ëœ ML ì—”ì§„ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    engine = AdvancedMLEngine()
    
    try:
        # í•œêµ­ ì‹œì¥ ê³ ë„í™”ëœ ëª¨ë¸ í•™ìŠµ
        print("\n1ï¸âƒ£ í•œêµ­ ì‹œì¥ ê³ ë„í™”ëœ ëª¨ë¸ í•™ìŠµ")
        kr_success = await engine.train_advanced_models(MarketRegion.KR)
        
        if kr_success:
            print("âœ… í•œêµ­ ì‹œì¥ í•™ìŠµ ì„±ê³µ")
            
            # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
            print("\n2ï¸âƒ£ í•œêµ­ ì‹œì¥ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸")
            kr_predictions = await engine.predict_with_advanced_models(MarketRegion.KR, top_n=5)
            
            for pred in kr_predictions:
                print(f"   {pred['stock_code']}: {pred['predicted_return']:.2f}% (ì‹ ë¢°ë„: {pred['confidence']:.2f})")
        
        # ë¯¸êµ­ ì‹œì¥ (ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬)
        # us_success = await engine.train_advanced_models(MarketRegion.US)
        
        print("\nğŸ‰ ê³ ë„í™”ëœ ML ì—”ì§„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        return True
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    import asyncio
    success = asyncio.run(main())
    sys.exit(0 if success else 1)
