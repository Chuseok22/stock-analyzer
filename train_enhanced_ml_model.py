#!/usr/bin/env python3
"""
ìƒˆë¡œìš´ ìŠ¤í‚¤ë§ˆì— ìµœì í™”ëœ ML ëª¨ë¸ í•™ìŠµ ë° ì¶”ì²œ ì‹œìŠ¤í…œ
ëŒ€ê·œëª¨ ì„œë¹„ìŠ¤ì™€ ê³ í’ˆì§ˆ ë°ì´í„°ë¥¼ í™œìš©í•œ ìˆ˜ìµë¥  ìµœì í™”
"""
import sys
from pathlib import Path
from datetime import datetime, date, timedelta
from typing import List, Dict, Any, Optional
import pandas as pd
import numpy as np
from decimal import Decimal

# Add app directory to path
sys.path.append(str(Path(__file__).parent / "app"))

from app.database.connection import get_db_session
from app.models.entities import (
    StockMaster, StockDailyPrice, StockTechnicalIndicator,
    TradingUniverse, TradingUniverseItem, StockRecommendation
)
from app.database.redis_client import redis_client


class EnhancedMLTrainer:
    """í–¥ìƒëœ ML ëª¨ë¸ í•™ìŠµê¸°"""
    
    def __init__(self):
        self.universe_id = 1  # ê¸°ë³¸ í•œêµ­ ìœ ë‹ˆë²„ìŠ¤
        self.prediction_days = [1, 5, 20]  # ì˜ˆì¸¡ ê¸°ê°„
    
    def verify_data_availability(self) -> Dict[str, Any]:
        """í•™ìŠµ ë°ì´í„° ê°€ìš©ì„± í™•ì¸"""
        print("ğŸ” í•™ìŠµ ë°ì´í„° ê°€ìš©ì„± í™•ì¸...")
        
        try:
            with get_db_session() as db:
                # ìœ ë‹ˆë²„ìŠ¤ ì •ë³´
                universe = db.query(TradingUniverse).filter(
                    TradingUniverse.universe_id == self.universe_id
                ).first()
                
                if not universe:
                    return {"success": False, "error": "ìœ ë‹ˆë²„ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
                
                # ìœ ë‹ˆë²„ìŠ¤ ì¢…ëª© ìˆ˜
                universe_stocks = db.query(TradingUniverseItem).filter(
                    TradingUniverseItem.universe_id == self.universe_id,
                    TradingUniverseItem.is_active == True
                ).count()
                
                # ì£¼ê°€ ë°ì´í„° ìˆ˜
                price_data_count = db.query(StockDailyPrice).join(
                    TradingUniverseItem,
                    StockDailyPrice.stock_id == TradingUniverseItem.stock_id
                ).filter(
                    TradingUniverseItem.universe_id == self.universe_id,
                    TradingUniverseItem.is_active == True
                ).count()
                
                # ê¸°ìˆ ì  ì§€í‘œ ë°ì´í„° ìˆ˜
                indicator_data_count = db.query(StockTechnicalIndicator).join(
                    TradingUniverseItem,
                    StockTechnicalIndicator.stock_id == TradingUniverseItem.stock_id
                ).filter(
                    TradingUniverseItem.universe_id == self.universe_id,
                    TradingUniverseItem.is_active == True
                ).count()
                
                # ë°ì´í„° ë‚ ì§œ ë²”ìœ„
                from sqlalchemy import text
                date_range = db.execute(text("""
                    SELECT 
                        MIN(sp.trade_date) as min_date,
                        MAX(sp.trade_date) as max_date
                    FROM stock_daily_price sp
                    INNER JOIN trading_universe_item tui ON sp.stock_id = tui.stock_id
                    WHERE tui.universe_id = :universe_id AND tui.is_active = true
                """), {"universe_id": self.universe_id}).fetchone()
                
                return {
                    "success": True,
                    "universe_name": universe.universe_name,
                    "universe_stocks": universe_stocks,
                    "price_data_count": price_data_count,
                    "indicator_data_count": indicator_data_count,
                    "date_range": {
                        "start": date_range.min_date,
                        "end": date_range.max_date
                    }
                }
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def create_ml_dataset(self) -> Optional[pd.DataFrame]:
        """ML í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„±"""
        print("ğŸ“Š ML í•™ìŠµìš© ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        try:
            with get_db_session() as db:
                # í†µí•© ë°ì´í„° ì¿¼ë¦¬ (ì£¼ê°€ + ê¸°ìˆ ì  ì§€í‘œ)
                from sqlalchemy import text
                query = text("""
                    SELECT 
                        sm.stock_id,
                        sm.stock_code,
                        sm.stock_name,
                        sm.sector_classification,
                        sp.trade_date,
                        sp.open_price,
                        sp.high_price,
                        sp.low_price,
                        sp.close_price,
                        sp.volume,
                        sp.volume_value,
                        sp.daily_return_pct,
                        sp.price_change_pct,
                        sp.vwap,
                        sp.typical_price,
                        sp.true_range,
                        sti.sma_5,
                        sti.sma_10,
                        sti.sma_20,
                        sti.sma_50,
                        sti.ema_12,
                        sti.ema_26,
                        sti.rsi_14,
                        sti.macd_line,
                        sti.macd_signal,
                        sti.macd_histogram,
                        sti.bb_upper_20_2,
                        sti.bb_middle_20,
                        sti.bb_lower_20_2,
                        sti.bb_width,
                        sti.bb_percent,
                        sti.volume_sma_20,
                        sti.volume_ratio,
                        sti.volatility_20
                    FROM stock_master sm
                    INNER JOIN trading_universe_item tui ON sm.stock_id = tui.stock_id
                    INNER JOIN stock_daily_price sp ON sm.stock_id = sp.stock_id
                    INNER JOIN stock_technical_indicator sti ON sm.stock_id = sti.stock_id 
                        AND sp.trade_date = sti.calculation_date
                    WHERE tui.universe_id = :universe_id 
                        AND tui.is_active = true
                        AND sp.trade_date >= :start_date
                    ORDER BY sm.stock_id, sp.trade_date
                """)
                
                # ìµœê·¼ 30ì¼ ë°ì´í„°
                start_date = datetime.now().date() - timedelta(days=30)
                
                result = db.execute(query, {
                    "universe_id": self.universe_id,
                    "start_date": start_date
                }).fetchall()
                
                if not result:
                    print("âŒ í•™ìŠµìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
                    return None
                
                # DataFrame ìƒì„±
                df = pd.DataFrame(result)
                print(f"âœ… ì´ {len(df)}ê°œ í•™ìŠµ ìƒ˜í”Œ ìƒì„±")
                
                # ë°ì´í„° íƒ€ì… ë³€í™˜
                numeric_columns = [
                    'open_price', 'high_price', 'low_price', 'close_price',
                    'volume', 'volume_value', 'daily_return_pct', 'price_change_pct',
                    'vwap', 'typical_price', 'true_range',
                    'sma_5', 'sma_10', 'sma_20', 'sma_50',
                    'ema_12', 'ema_26', 'rsi_14',
                    'macd_line', 'macd_signal', 'macd_histogram',
                    'bb_upper_20_2', 'bb_middle_20', 'bb_lower_20_2',
                    'bb_width', 'bb_percent', 'volume_sma_20', 'volume_ratio',
                    'volatility_20'
                ]
                
                for col in numeric_columns:
                    if col in df.columns:
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                
                # ë‚ ì§œ ë³€í™˜
                df['trade_date'] = pd.to_datetime(df['trade_date'])
                
                return df
                
        except Exception as e:
            print(f"âŒ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def create_target_variables(self, df: pd.DataFrame) -> pd.DataFrame:
        """íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ë¯¸ë˜ ìˆ˜ìµë¥ )"""
        print("ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì¤‘...")
        
        try:
            # ê° ì¢…ëª©ë³„ë¡œ ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
            result_dfs = []
            
            for stock_id in df['stock_id'].unique():
                stock_df = df[df['stock_id'] == stock_id].copy()
                stock_df = stock_df.sort_values('trade_date').reset_index(drop=True)
                
                # ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
                for days in self.prediction_days:
                    future_col = f'future_return_{days}d'
                    stock_df[future_col] = (
                        stock_df['close_price'].shift(-days) / stock_df['close_price'] - 1
                    ) * 100
                
                # ë¶„ë¥˜ íƒ€ê²Ÿ (ìƒìŠ¹/í•˜ë½)
                stock_df['target_1d_up'] = (stock_df['future_return_1d'] > 0).astype(int)
                stock_df['target_5d_up'] = (stock_df['future_return_5d'] > 0).astype(int)
                stock_df['target_20d_up'] = (stock_df['future_return_20d'] > 0).astype(int)
                
                # ê°•í•œ ìƒìŠ¹ íƒ€ê²Ÿ (3% ì´ìƒ)
                stock_df['target_1d_strong'] = (stock_df['future_return_1d'] > 3.0).astype(int)
                stock_df['target_5d_strong'] = (stock_df['future_return_5d'] > 5.0).astype(int)
                stock_df['target_20d_strong'] = (stock_df['future_return_20d'] > 10.0).astype(int)
                
                result_dfs.append(stock_df)
            
            final_df = pd.concat(result_dfs, ignore_index=True)
            
            # ë¯¸ë˜ ë°ì´í„°ê°€ ì—†ëŠ” í–‰ ì œê±°
            final_df = final_df.dropna(subset=[f'future_return_{days}d' for days in self.prediction_days])
            
            print(f"âœ… íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì™„ë£Œ: {len(final_df)}ê°œ ìƒ˜í”Œ")
            return final_df
            
        except Exception as e:
            print(f"âŒ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì‹¤íŒ¨: {e}")
            return df
    
    def create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§"""
        print("ğŸ”§ ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì¤‘...")
        
        try:
            result_dfs = []
            
            for stock_id in df['stock_id'].unique():
                stock_df = df[df['stock_id'] == stock_id].copy()
                stock_df = stock_df.sort_values('trade_date').reset_index(drop=True)
                
                # ê°€ê²© ê´€ë ¨ í”¼ì²˜
                stock_df['price_momentum_5'] = (
                    stock_df['close_price'] / stock_df['close_price'].shift(5) - 1
                ) * 100
                
                stock_df['price_momentum_10'] = (
                    stock_df['close_price'] / stock_df['close_price'].shift(10) - 1
                ) * 100
                
                # ìƒëŒ€ ê°•ë„
                stock_df['price_vs_sma20'] = (
                    stock_df['close_price'] / stock_df['sma_20'] - 1
                ) * 100
                
                stock_df['price_vs_sma50'] = (
                    stock_df['close_price'] / stock_df['sma_50'] - 1
                ) * 100
                
                # ë³¼ë¥¨ ê´€ë ¨ í”¼ì²˜
                stock_df['volume_momentum'] = (
                    stock_df['volume'] / stock_df['volume'].shift(5) - 1
                ) * 100
                
                # ë³€ë™ì„± ê´€ë ¨ í”¼ì²˜
                stock_df['volatility_zscore'] = (
                    stock_df['volatility_20'] - stock_df['volatility_20'].rolling(10).mean()
                ) / stock_df['volatility_20'].rolling(10).std()
                
                # ê¸°ìˆ ì  ì§€í‘œ ì¡°í•©
                if 'ema_12' in stock_df.columns and 'ema_26' in stock_df.columns:
                    stock_df['ema_convergence'] = stock_df['ema_12'] - stock_df['ema_26']
                
                # RSI ê´€ë ¨ í”¼ì²˜
                if 'rsi_14' in stock_df.columns:
                    stock_df['rsi_overbought'] = (stock_df['rsi_14'] > 70).astype(int)
                    stock_df['rsi_oversold'] = (stock_df['rsi_14'] < 30).astype(int)
                
                # ë³¼ë¦°ì € ë°´ë“œ ê´€ë ¨ í”¼ì²˜
                if 'bb_percent' in stock_df.columns:
                    stock_df['bb_squeeze'] = (stock_df['bb_width'] < stock_df['bb_width'].rolling(10).quantile(0.2)).astype(int)
                
                # íŠ¸ë Œë“œ ê´€ë ¨ í”¼ì²˜
                stock_df['trend_strength'] = stock_df['sma_20'].pct_change(5) * 100
                
                # ê°€ê²© íŒ¨í„´
                stock_df['near_high'] = (
                    stock_df['close_price'] / stock_df['high_price'].rolling(20).max()
                )
                
                stock_df['near_low'] = (
                    stock_df['close_price'] / stock_df['low_price'].rolling(20).min()
                )
                
                result_dfs.append(stock_df)
            
            final_df = pd.concat(result_dfs, ignore_index=True)
            print(f"âœ… í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ: {len(final_df.columns)}ê°œ í”¼ì²˜")
            
            return final_df
            
        except Exception as e:
            print(f"âŒ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return df
    
    def train_ml_models(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ML ëª¨ë¸ í•™ìŠµ"""
        print("ğŸ¤– ML ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        
        try:
            from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
            from sklearn.linear_model import LogisticRegression
            from sklearn.model_selection import train_test_split, cross_val_score
            from sklearn.metrics import classification_report, accuracy_score
            from sklearn.preprocessing import StandardScaler
            import pickle
            
            # í”¼ì²˜ ì„ íƒ
            feature_columns = [
                'daily_return_pct', 'price_change_pct', 'volume_ratio',
                'rsi_14', 'macd_line', 'bb_percent',
                'price_momentum_5', 'price_momentum_10',
                'price_vs_sma20', 'price_vs_sma50',
                'volume_momentum', 'volatility_zscore',
                'trend_strength', 'near_high', 'near_low'
            ]
            
            # ì¡´ì¬í•˜ëŠ” í”¼ì²˜ë§Œ ì„ íƒ
            available_features = [col for col in feature_columns if col in df.columns]
            print(f"ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜: {len(available_features)}ê°œ")
            
            if len(available_features) < 5:
                return {"success": False, "error": "ì¶©ë¶„í•œ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤"}
            
            # ë°ì´í„° ì¤€ë¹„
            X = df[available_features].fillna(0)
            y = df['target_1d_up']  # 1ì¼ í›„ ìƒìŠ¹ ì˜ˆì¸¡
            
            # NaN ì œê±°
            mask = ~(X.isna().any(axis=1) | y.isna())
            X = X[mask]
            y = y[mask]
            
            if len(X) < 50:
                return {"success": False, "error": f"í•™ìŠµ ë°ì´í„° ë¶€ì¡±: {len(X)}ê°œ"}
            
            print(f"âœ… í•™ìŠµ ë°ì´í„° ì¤€ë¹„: {len(X)}ê°œ ìƒ˜í”Œ")
            
            # ë°ì´í„° ë¶„í• 
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
            
            # ìŠ¤ì¼€ì¼ë§
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            X_test_scaled = scaler.transform(X_test)
            
            # ëª¨ë¸ í•™ìŠµ
            models = {
                'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),
                'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
                'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000)
            }
            
            model_results = {}
            best_model = None
            best_score = 0
            
            for name, model in models.items():
                print(f"ğŸ”„ {name} ëª¨ë¸ í•™ìŠµ ì¤‘...")
                
                if name == 'LogisticRegression':
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                else:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                
                accuracy = accuracy_score(y_test, y_pred)
                cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
                
                model_results[name] = {
                    'accuracy': accuracy,
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std(),
                    'model': model
                }
                
                print(f"   ì •í™•ë„: {accuracy:.4f}")
                print(f"   CV í‰ê· : {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")
                
                if accuracy > best_score:
                    best_score = accuracy
                    best_model = model
                    best_model_name = name
            
            # ìµœì  ëª¨ë¸ ì €ì¥
            model_path = Path(__file__).parent / "models"
            model_path.mkdir(exist_ok=True)
            
            with open(model_path / "best_model.pkl", "wb") as f:
                pickle.dump(best_model, f)
            
            with open(model_path / "scaler.pkl", "wb") as f:
                pickle.dump(scaler, f)
            
            with open(model_path / "features.pkl", "wb") as f:
                pickle.dump(available_features, f)
            
            return {
                "success": True,
                "best_model": best_model_name,
                "best_accuracy": best_score,
                "training_samples": len(X_train),
                "test_samples": len(X_test),
                "features_count": len(available_features),
                "model_results": {name: {k: v for k, v in result.items() if k != 'model'} 
                                for name, result in model_results.items()}
            }
            
        except Exception as e:
            print(f"âŒ ML ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return {"success": False, "error": str(e)}
    
    def generate_predictions(self) -> List[Dict[str, Any]]:
        """ìµœì‹  ë°ì´í„°ë¡œ ì˜ˆì¸¡ ìƒì„±"""
        print("ğŸ“ˆ ì˜ˆì¸¡ ìƒì„± ì¤‘...")
        
        try:
            import pickle
            from datetime import datetime
            
            model_path = Path(__file__).parent / "models"
            
            # ëª¨ë¸ ë¡œë“œ
            with open(model_path / "best_model.pkl", "rb") as f:
                model = pickle.load(f)
            
            with open(model_path / "scaler.pkl", "rb") as f:
                scaler = pickle.load(f)
            
            with open(model_path / "features.pkl", "rb") as f:
                features = pickle.load(f)
            
            # ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            df = self.create_ml_dataset()
            if df is None:
                return []
            
            df = self.create_features(df)
            
            # ìµœì‹  ë‚ ì§œ ë°ì´í„°ë§Œ ì„ íƒ
            latest_date = df['trade_date'].max()
            latest_df = df[df['trade_date'] == latest_date].copy()
            
            if len(latest_df) == 0:
                return []
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            X = latest_df[features].fillna(0)
            
            if hasattr(model, 'predict_proba'):
                # í™•ë¥  ì˜ˆì¸¡
                if 'LogisticRegression' in str(type(model)):
                    X_scaled = scaler.transform(X)
                    predictions = model.predict_proba(X_scaled)[:, 1]
                else:
                    predictions = model.predict_proba(X)[:, 1]
            else:
                predictions = model.predict(X)
            
            # ê²°ê³¼ ìƒì„±
            results = []
            for i, (_, row) in enumerate(latest_df.iterrows()):
                results.append({
                    'stock_id': int(row['stock_id']),
                    'stock_code': row['stock_code'],
                    'stock_name': row['stock_name'],
                    'prediction_score': float(predictions[i]),
                    'prediction_date': latest_date.date(),
                    'target_date': (latest_date + timedelta(days=1)).date()
                })
            
            # ì ìˆ˜ìˆœ ì •ë ¬
            results.sort(key=lambda x: x['prediction_score'], reverse=True)
            
            print(f"âœ… {len(results)}ê°œ ì¢…ëª© ì˜ˆì¸¡ ì™„ë£Œ")
            return results
            
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def save_recommendations(self, predictions: List[Dict[str, Any]], top_n: int = 10) -> int:
        """ì¶”ì²œ ê²°ê³¼ ì €ì¥"""
        print(f"ğŸ’¾ ìƒìœ„ {top_n}ê°œ ì¶”ì²œ ì €ì¥ ì¤‘...")
        
        try:
            saved_count = 0
            
            with get_db_session() as db:
                for rank, pred in enumerate(predictions[:top_n], 1):
                    # ê¸°ì¡´ ì¶”ì²œ í™•ì¸
                    existing_rec = db.query(StockRecommendation).filter(
                        StockRecommendation.stock_id == pred['stock_id'],
                        StockRecommendation.recommendation_date == pred['prediction_date']
                    ).first()
                    
                    if existing_rec:
                        # ê¸°ì¡´ ì¶”ì²œ ì—…ë°ì´íŠ¸
                        existing_rec.ml_score = pred['prediction_score']
                        existing_rec.universe_rank = rank
                        existing_rec.model_name = "Enhanced ML Model"
                        existing_rec.model_version = "v2.0"
                        existing_rec.updated_at = datetime.now()
                    else:
                        # ìƒˆë¡œìš´ ì¶”ì²œ ìƒì„±
                        new_rec = StockRecommendation(
                            stock_id=pred['stock_id'],
                            universe_id=self.universe_id,
                            recommendation_date=pred['prediction_date'],
                            target_date=pred['target_date'],
                            ml_score=pred['prediction_score'],
                            universe_rank=rank,
                            model_name="Enhanced ML Model",
                            model_version="v2.0",
                            recommendation_reason=f"ML Score: {pred['prediction_score']:.4f}"
                        )
                        db.add(new_rec)
                        saved_count += 1
                
                db.commit()
            
            print(f"âœ… {saved_count}ê°œ ì¶”ì²œ ì €ì¥ ì™„ë£Œ")
            return saved_count
            
        except Exception as e:
            print(f"âŒ ì¶”ì²œ ì €ì¥ ì‹¤íŒ¨: {e}")
            return 0


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ í–¥ìƒëœ ML ëª¨ë¸ í•™ìŠµ ë° ì¶”ì²œ ì‹œìŠ¤í…œ")
    print("="*70)
    print("ğŸ“‹ ì‘ì—… ìˆœì„œ:")
    print("1. ë°ì´í„° ê°€ìš©ì„± í™•ì¸")
    print("2. ML ë°ì´í„°ì…‹ ìƒì„±")
    print("3. íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±")
    print("4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§")
    print("5. ML ëª¨ë¸ í•™ìŠµ")
    print("6. ì˜ˆì¸¡ ìƒì„±")
    print("7. ì¶”ì²œ ì €ì¥")
    print("="*70)
    
    trainer = EnhancedMLTrainer()
    
    # 1ë‹¨ê³„: ë°ì´í„° ê°€ìš©ì„± í™•ì¸
    print("\n1ï¸âƒ£ ë°ì´í„° ê°€ìš©ì„± í™•ì¸")
    data_check = trainer.verify_data_availability()
    
    if not data_check["success"]:
        print(f"âŒ ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {data_check['error']}")
        return False
    
    print(f"âœ… ìœ ë‹ˆë²„ìŠ¤: {data_check['universe_name']}")
    print(f"âœ… ì¢…ëª© ìˆ˜: {data_check['universe_stocks']}ê°œ")
    print(f"âœ… ì£¼ê°€ ë°ì´í„°: {data_check['price_data_count']}ê°œ")
    print(f"âœ… ê¸°ìˆ ì  ì§€í‘œ: {data_check['indicator_data_count']}ê°œ")
    print(f"âœ… ë°ì´í„° ê¸°ê°„: {data_check['date_range']['start']} ~ {data_check['date_range']['end']}")
    
    # 2ë‹¨ê³„: ML ë°ì´í„°ì…‹ ìƒì„±
    print("\n2ï¸âƒ£ ML ë°ì´í„°ì…‹ ìƒì„±")
    df = trainer.create_ml_dataset()
    
    if df is None:
        print("âŒ ë°ì´í„°ì…‹ ìƒì„± ì‹¤íŒ¨")
        return False
    
    # 3ë‹¨ê³„: íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±
    print("\n3ï¸âƒ£ íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±")
    df = trainer.create_target_variables(df)
    
    # 4ë‹¨ê³„: í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§
    print("\n4ï¸âƒ£ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§")
    df = trainer.create_features(df)
    
    # 5ë‹¨ê³„: ML ëª¨ë¸ í•™ìŠµ
    print("\n5ï¸âƒ£ ML ëª¨ë¸ í•™ìŠµ")
    training_result = trainer.train_ml_models(df)
    
    if not training_result["success"]:
        print(f"âŒ ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨: {training_result['error']}")
        return False
    
    print(f"âœ… ìµœì  ëª¨ë¸: {training_result['best_model']}")
    print(f"âœ… ìµœê³  ì •í™•ë„: {training_result['best_accuracy']:.4f}")
    print(f"âœ… í•™ìŠµ ìƒ˜í”Œ: {training_result['training_samples']}ê°œ")
    print(f"âœ… í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {training_result['test_samples']}ê°œ")
    print(f"âœ… í”¼ì²˜ ìˆ˜: {training_result['features_count']}ê°œ")
    
    # 6ë‹¨ê³„: ì˜ˆì¸¡ ìƒì„±
    print("\n6ï¸âƒ£ ì˜ˆì¸¡ ìƒì„±")
    predictions = trainer.generate_predictions()
    
    if not predictions:
        print("âŒ ì˜ˆì¸¡ ìƒì„± ì‹¤íŒ¨")
        return False
    
    print(f"âœ… {len(predictions)}ê°œ ì¢…ëª© ì˜ˆì¸¡ ì™„ë£Œ")
    
    # ìƒìœ„ 10ê°œ ì˜ˆì¸¡ ì¶œë ¥
    print("\nğŸ† ìƒìœ„ 10ê°œ ì˜ˆì¸¡:")
    for i, pred in enumerate(predictions[:10], 1):
        print(f"   {i}. {pred['stock_code']} ({pred['stock_name']}) - ì ìˆ˜: {pred['prediction_score']:.4f}")
    
    # 7ë‹¨ê³„: ì¶”ì²œ ì €ì¥
    print("\n7ï¸âƒ£ ì¶”ì²œ ì €ì¥")
    saved_count = trainer.save_recommendations(predictions, top_n=10)
    
    # ì„±ê³µ ìš”ì•½
    print("\n" + "="*70)
    print("ğŸ‰ í–¥ìƒëœ ML ëª¨ë¸ í•™ìŠµ ë° ì¶”ì²œ ì‹œìŠ¤í…œ ì™„ë£Œ!")
    print("="*70)
    print(f"âœ… ìµœì  ëª¨ë¸: {training_result['best_model']}")
    print(f"âœ… ëª¨ë¸ ì •í™•ë„: {training_result['best_accuracy']:.4f}")
    print(f"âœ… í•™ìŠµ ë°ì´í„°: {training_result['training_samples']}ê°œ")
    print(f"âœ… ì˜ˆì¸¡ ì¢…ëª©: {len(predictions)}ê°œ")
    print(f"âœ… ì €ì¥ëœ ì¶”ì²œ: {saved_count}ê°œ")
    print("\nğŸš€ ì¶”ì²œ ì‹œìŠ¤í…œì´ ì™„ì „íˆ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # Discord ì•Œë¦¼
    try:
        from app.services.notification import NotificationService
        notification = NotificationService()
        
        # ìƒìœ„ 5ê°œ ì¶”ì²œ í¬ë§·íŒ…
        top_5_text = "\n".join([
            f"{i}. {pred['stock_code']} ({pred['stock_name']}) - {pred['prediction_score']:.4f}"
            for i, pred in enumerate(predictions[:5], 1)
        ])
        
        message = (
            f"ğŸ¤– **í–¥ìƒëœ ML ëª¨ë¸ í•™ìŠµ ì™„ë£Œ**\n\n"
            f"ğŸ“… í•™ìŠµ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"ğŸ¯ ìµœì  ëª¨ë¸: {training_result['best_model']}\n"
            f"ğŸ“Š ëª¨ë¸ ì •í™•ë„: {training_result['best_accuracy']:.4f}\n"
            f"ğŸ”¢ í•™ìŠµ ìƒ˜í”Œ: {training_result['training_samples']}ê°œ\n"
            f"ğŸ”§ í”¼ì²˜ ìˆ˜: {training_result['features_count']}ê°œ\n\n"
            f"ğŸ† **ìƒìœ„ 5ê°œ ì¶”ì²œ:**\n{top_5_text}\n\n"
            f"âœ… **ì¶”ì²œ ì‹œìŠ¤í…œ ì™„ì „ ì¤€ë¹„!**"
        )
        notification._send_simple_slack_message(message)
        print("ğŸ“± Discord ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ Discord ì•Œë¦¼ ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
